{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d30e89",
   "metadata": {},
   "source": [
    "## Loading functions\n",
    "\n",
    "here we export the stimdf's needed in order to run drex matlab scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f243861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py loading function for big matlab file loading\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a564eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/jorvhar/50550017.dccn-l029.dccn.nl/ipykernel_10178/2947205692.py:23: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, log_loss\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import norm\n",
    "import scipy.io\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import contextlib\n",
    "from copy import deepcopy\n",
    "import imp \n",
    "import time \n",
    "import sys\n",
    "\n",
    "import adaptation.longtrace_adaptation as longtrace_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb0c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING FUNCTIONS\n",
    "\n",
    "# main loading\n",
    "def data_load(pp,data_dir, stim_dir):\n",
    "    \"\"\"load mainpred mat file and stimuli matfile\"\"\"\n",
    "    mat = scipy.io.loadmat(join(data_dir,\n",
    "                                f'{pp}-mainpred.mat'))\n",
    "    stimuli = scipy.io.loadmat(join(stim_dir, \n",
    "                                    f'{pp}_main_stims.mat'))\n",
    "    return(mat, stimuli)\n",
    "\n",
    "\n",
    "def stims_load(mat, stimuli):\n",
    "    \"\"\"using information from stimuli and pulse timing create dataframe \n",
    "    with frequency information, pulse location etc.\n",
    "    note: 'volume_rel' & 'vol_abs' are the volume where this stimuli was measured\n",
    "    'closest_volume_rel' & 'closest_volume_abs' are the volume which is the closest in time\n",
    "    (half tr shift) - since a tr should capture information within that tr\"\"\"\n",
    "\n",
    "    # set arrays\n",
    "    freqz   = np.array([])\n",
    "    timingz  = np.array([])\n",
    "    timings_offsetz  = np.array([])\n",
    "    runz     = np.array([])\n",
    "    blockz   = np.array([])\n",
    "    segmenz  = np.array([])\n",
    "    centaz   = np.array([])\n",
    "    centbz   = np.array([])\n",
    "    probaz   = np.array([])\n",
    "    probbz   = np.array([])\n",
    "\n",
    "    for blk in np.arange(1, mat['timingz'][1].max()+1):\n",
    "        # get blockidx\n",
    "        idxblock = np.where(mat['timingz'][1] == blk) # where block is 1\n",
    "\n",
    "        #get frequency presentation data for block\n",
    "        frequencies = stimuli['pres_freq'][int(blk)-1, :]\n",
    "\n",
    "        # other values\n",
    "        tps = np.sum(mat['timingz'][3, idxblock] == 1) # get trials per secion\n",
    "\n",
    "        #get timings back from mat file, substract begin time\n",
    "        timings = mat['timingz'][6, idxblock]\n",
    "        timings_offset = mat['timingz'][7, idxblock]\n",
    "        matidx = np.where(mat['segmentz'][1] == blk)\n",
    "\n",
    "        # append to arrays\n",
    "        freqz = np.append(freqz, frequencies)\n",
    "        timingz = np.append(timingz, timings)\n",
    "        timings_offsetz = np.append(timings_offsetz, timings_offset)\n",
    "        runz = np.append(runz, np.repeat(mat['segmentz'][0][matidx], tps))\n",
    "        blockz = np.append(blockz, np.repeat(mat['segmentz'][1][matidx], tps))\n",
    "        segmenz = np.append(segmenz, np.repeat(mat['segmentz'][2][matidx], tps))\n",
    "        centaz = np.append(centaz, 2**np.repeat(mat['segmentz'][7][matidx], tps))   # cent freq a\n",
    "        centbz = np.append(centbz, 2**np.repeat(mat['segmentz'][8][matidx], tps))  # cent freq b\n",
    "        probaz = np.append(probaz, np.repeat(mat['segmentz'][5][matidx], tps))\n",
    "        probbz = np.append(probbz, np.repeat(mat['segmentz'][6][matidx], tps))\n",
    "\n",
    "    # oct variant \n",
    "    freqz_oct = np.log2(freqz)\n",
    "    centaz_oct = np.log2(centaz)\n",
    "    centbz_oct = np.log2(centbz)\n",
    "\n",
    "    # put data into a dictionary and subsequentially in a dataframe\n",
    "    stim_df_dict = {'frequencies': freqz,\n",
    "                    'frequencies_oct': freqz_oct,\n",
    "                    'timing': timingz,\n",
    "                    'timing_offset': timings_offsetz,\n",
    "                    'run': runz,\n",
    "                    'block': blockz,\n",
    "                    'segment': segmenz,\n",
    "                    'center_freq_a': centaz,\n",
    "                    'center_freq_b': centbz,\n",
    "                    'center_freq_a_oct': centaz_oct,\n",
    "                    'center_freq_b_oct': centbz_oct,\n",
    "                    'probability_a': probaz,\n",
    "                    'probability_b': probbz\n",
    "                   }\n",
    "\n",
    "    stim_df = pd.DataFrame(stim_df_dict)\n",
    "    # Add the 'stimulus' column to df_beh\n",
    "    stim_df['stimulus'] = stim_df.index + 1\n",
    "    return(stim_df)\n",
    "\n",
    "\n",
    "def sync_timing(df, sync_val, timingname='timing', new_timingname='timing_meg',\n",
    "                              timingname_offset='timing_offset', new_timingname_offset='timing_offset_meg'):\n",
    "    \"\"\"use syncing value to get timings from stimpc domain into the MEG clock domain\n",
    "    input df and sync value, returns adjusted dataframe\"\"\"\n",
    "\n",
    "    # create new column in old dataframe\n",
    "    df[new_timingname] = df[timingname] + sync_val\n",
    "    df[new_timingname_offset] = df[timingname_offset] + sync_val\n",
    "    # and return\n",
    "    return(df)\n",
    "\n",
    "def plot_design_mat(tr_df, all_freqs, pref1, tw1, pref2, tw2, runs=1):\n",
    "    \"\"\"plot the desing matrix for two tuning functions specified\"\"\"\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # check if runs in list, else place in list\n",
    "    runs = [runs] if isinstance(runs, int) else runs\n",
    "\n",
    "    # create subplots\n",
    "    fig, ax = plt.subplots(2,\n",
    "                           2,\n",
    "                           figsize=(13,13), gridspec_kw={'height_ratios': [2, 3]})\n",
    "\n",
    "    # make x the full range\n",
    "    x = all_freqs\n",
    "\n",
    "    # calculate the normal function for all frequency points\n",
    "    y1 = gauss(x, pref1, tw1)\n",
    "    y2 = gauss(x, pref2, tw2)\n",
    "\n",
    "    # plot the first gaussian functions\n",
    "    ax[0, 0].plot(x,y1, color='darkgreen', lw=3)\n",
    "\n",
    "    # pimp the first gaussian function\n",
    "    ax[0, 0].tick_params(axis='x', which='major', labelsize=18)               # set ticksizes x \n",
    "    ax[0, 0].tick_params(axis='y', which='major', labelsize=18)               # and y\n",
    "    ax[0, 0].set_ylabel(f'Activation', fontsize=18) \n",
    "    ax[0, 0].set_xlabel(f'Freq - oct', fontsize=18) \n",
    "    ax[0, 0].spines['top'].set_visible(False)\n",
    "    ax[0, 0].spines['right'].set_visible(False)\n",
    "    ax[0, 0].set_title(f'Freq: {2**pref1:.1f}kHz\\nTW-FWHM: {tw1 * 2.354:.2f}oct', fontsize=22)\n",
    "\n",
    "    # plot the second gaussian fucntion\n",
    "    ax[0, 1].plot(x,y2, color='darkgreen', lw=3)\n",
    "\n",
    "    # pimp the second gaussian function\n",
    "    ax[0, 1].tick_params(axis='x', which='major', labelsize=18)               # and y\n",
    "    ax[0, 1].set_xlabel(f'Freq - oct', fontsize=18) \n",
    "    ax[0, 1].axes.get_yaxis().set_visible(False)\n",
    "    ax[0, 1].spines['top'].set_visible(False)\n",
    "    ax[0, 1].spines['right'].set_visible(False)\n",
    "    ax[0, 1].spines['left'].set_visible(False)\n",
    "    ax[0, 1].set_title(f'Freq: {2**pref2:.1f}kHz\\nTW-FWHM: {tw2 * 2.354:.2f}oct', fontsize=22)\n",
    "\n",
    "    # from the tuning width and tuning pref get the columns of interest\n",
    "    colls = get_tw_collumns(tr_df, pref1, tw1, convolved=True)\n",
    "    del colls[-2]                    # remove adapted activation\n",
    "    colls += ['onoff']     # add onoff\n",
    "\n",
    "    # plot the first heatmap \n",
    "    sns.heatmap(normalize(tr_df[colls][tr_df['run'].isin(runs)]),cmap=\"crest\", cbar=False, \n",
    "                ax=ax[1,0])\n",
    "\n",
    "    # pimp the first heat map\n",
    "    ax[1, 0].set_ylabel(f'Trial', fontsize=18) \n",
    "    ax[1, 0].tick_params(axis='x', which='major', labelsize=14)               # set ticksizes x \n",
    "    ax[1, 0].axes.yaxis.set_ticklabels([])\n",
    "\n",
    "    # from the second tuning widt and tuning pref get the columns of interest\n",
    "    colls = get_tw_collumns(tr_df, pref2, tw2, convolved=True)\n",
    "    del colls[-2]                    # remove adapted activation\n",
    "    colls += ['onoff']     # add onoff\n",
    "\n",
    "    # plot the second heatmap\n",
    "    sns.heatmap(normalize(tr_df[colls][tr_df['run'].isin(runs)]),cmap=\"crest\", cbar=False, \n",
    "                ax=ax[1,1])\n",
    "\n",
    "    # pimp the second heat map\n",
    "    ax[1, 1].axes.get_yaxis().set_visible(False)\n",
    "    ax[1, 1].tick_params(axis='x', which='major', labelsize=14)               # set ticksizes x \n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.plot()\n",
    "    return(ax,fig)\n",
    "\n",
    "\n",
    "def data_plot(mat, stimuli, blocknr=1, octvspace=False):\n",
    "    \"\"\"plot important aspects of raw data \n",
    "    optionally plot specific blocknr\"\"\"\n",
    "    ## PREPAIRING DATA\n",
    "    # where block is 1\n",
    "    idxblock = np.where(mat['timingz'][1] == blocknr) \n",
    "\n",
    "    #get frequency presentation data for block\n",
    "    frequencies = stimuli['pres_freq'][blocknr-1, :]\n",
    "\n",
    "    # other values\n",
    "    tps = np.sum(mat['timingz'][3, idxblock] == 1) # get trials per secion\n",
    "\n",
    "    #get timings back from mat file, substract begin time\n",
    "    timings = mat['timingz'][4, idxblock] - np.min(mat['timingz'][4, idxblock]) \n",
    "\n",
    "    matidx = np.where(mat['segmentz'][1] == blocknr)\n",
    "\n",
    "    centa = 2**np.repeat(mat['segmentz'][7][matidx], tps)   # cent freq a\n",
    "    centb = 2**np.repeat(mat['segmentz'][8][matidx], tps)  # cent freq b\n",
    "    proba = np.repeat(mat['segmentz'][5][matidx], tps)  # prob a\n",
    "    probb = np.repeat(mat['segmentz'][6][matidx], tps)  # prob b\n",
    "    \n",
    "    ## ACTUAL PLOTTING\n",
    "    # senatry check the data\n",
    "    fig, ax = plt.subplots(2, \n",
    "                           1, \n",
    "                           sharex=True,\n",
    "                           gridspec_kw={'height_ratios': [3, 1]}, figsize=(10,  7.5))\n",
    "\n",
    "    # octave transform if wanted\n",
    "    if octvspace: \n",
    "        frequencies = np.log2(frequencies)\n",
    "        centa = np.log2(centa)\n",
    "        centb = np.log2(centb)\n",
    "    \n",
    "    ax[0].scatter(timings, frequencies, color='darkslategrey', alpha=0.8)\n",
    "    ax[0].axhline(y=centa[0], color='darkred', linestyle='-', alpha=0.5, ls='--', lw=4)\n",
    "    ax[0].axhline(y=centb[0], color='darkred', linestyle='-', alpha=0.5, ls='--', lw=4)\n",
    "    ax[0].tick_params(axis='x', which='major', labelsize=18)               # set ticksizes x \n",
    "    ax[0].tick_params(axis='y', which='major', labelsize=18)               # and y\n",
    "    if octvspace: space = 'octaves'\n",
    "    else: space = 'Hz'\n",
    "    ax[0].set_ylabel(f'Frequencies - in {space}', fontsize=18) \n",
    "    \n",
    "    #ax[1].plot(timings[0], proba, color='r')\n",
    "    ax[1].plot(timings[0], probb, color='darkolivegreen', lw=8)\n",
    "    ax[1].tick_params(axis='x', which='major', labelsize=18)               # set ticksizes x \n",
    "    ax[1].tick_params(axis='y', which='major', labelsize=18)               # and y\n",
    "    ax[1].set_xlabel('Volume', fontsize=18)\n",
    "    ax[1].set_ylabel('Prob - top', fontsize=18) \n",
    "    \n",
    "    # pimp plot\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.suptitle(f'Stimuli over block {blocknr}', fontsize=26)\n",
    "    plt.tight_layout()\n",
    "    return(ax, fig)\n",
    "\n",
    "def stim_plot(stim_df):\n",
    "    ## ACTUAL PLOTTING\n",
    "    # senatry check the data\n",
    "    fig, ax = plt.subplots(2, \n",
    "                           1, \n",
    "                           sharex=True,\n",
    "                           gridspec_kw={'height_ratios': [3, 1]}, figsize=(10,  7.5))\n",
    "\n",
    "    ax[0].scatter(stim_df['timing'], stim_df['frequencies_oct'], color='darkslategrey', alpha=0.8)\n",
    "\n",
    "    ax[0].plot(stim_df['timing'], stim_df['center_freq_a_oct'], linestyle='-', alpha=0.5, lw=4)\n",
    "    ax[0].plot(stim_df['timing'], stim_df['center_freq_b_oct'], linestyle='-', alpha=0.5, lw=4)\n",
    "\n",
    "    ax[0].tick_params(axis='x', which='major', labelsize=18)               # set ticksizes x \n",
    "    ax[0].tick_params(axis='y', which='major', labelsize=18)               # and y\n",
    "    ax[0].set_ylabel(f'Frequencies (oct)', fontsize=18) \n",
    "\n",
    "    #ax[1].plot(timings[0], proba, color='r')\n",
    "    ax[1].plot(stim_df['timing'], stim_df['probability_a'], color='darkolivegreen', lw=8)\n",
    "    ax[1].tick_params(axis='x', which='major', labelsize=18)               # set ticksizes x \n",
    "    ax[1].tick_params(axis='y', which='major', labelsize=18)               # and y\n",
    "    ax[1].set_xlabel('Stimulus nr.', fontsize=18)\n",
    "    ax[1].set_ylabel('Prob - top', fontsize=18) \n",
    "\n",
    "    # pimp plot\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.suptitle(f'Stimuli', fontsize=26)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return(ax, fig)\n",
    "\n",
    "def freqs_plot(pref_range, sharp_range):\n",
    "    \"\"\"given a sharpness range and a prefference range plot all gaussians\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, \n",
    "                           1, \n",
    "                           sharex=True, figsize=(12,  3))\n",
    "\n",
    "    # predefine size of design matrix\n",
    "    y_data = np.zeros((len(pref_range), len(pref_range)*len(sharp_range)))\n",
    "    idx = 0\n",
    "    \n",
    "    # loop over tuning widths\n",
    "    for tw in sharp_range:\n",
    "        # loop over prefferences\n",
    "        for pref in pref_range:\n",
    "            y_data[:, idx] = gauss(pref_range, pref, tw)\n",
    "            idx += 1\n",
    "    plt.suptitle('Used Tuning Gaussians', fontsize=26)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(y_data)\n",
    "    return(ax, fig)\n",
    "\n",
    "def gauss(x, x0, sigma):\n",
    "    return np.exp(-(x - x0) ** 2 / (2 * sigma ** 2))\n",
    "\n",
    "\n",
    "def run_adaptation(stim_df, pref_range, sharp_range, y_decay):\n",
    "    \"\"\"wrapper functions to run adaptation model and return long matrixes of [pref*tw, stimuli]\"\"\"\n",
    "    \n",
    "    # calculate raw activation\n",
    "    stims = stim_df['frequencies_oct'].to_numpy()\n",
    "    activations = longtrace_adaptation.md_gaussian_activations(pref_range, sharp_range, stims)\n",
    "    adaptations = np.zeros([len(pref_range)*len(sharp_range), len(stims)])\n",
    "    n_back_adaptations = np.zeros([len(pref_range)*len(sharp_range), len(stims), len(y_decay)])\n",
    "\n",
    "    for blk in stim_df['block'].unique():\n",
    "        # get all stimuli within this block & get start and end idx of block\n",
    "        stims = stim_df['frequencies_oct'][stim_df['block'] == blk].to_numpy()\n",
    "        st_idx = stim_df.index[stim_df['block'] == blk][0]\n",
    "        nd_idx = stim_df.index[stim_df['block'] == blk][-1] + 1\n",
    "\n",
    "        # calculate adaptation for current block\n",
    "        adaptations[:, st_idx:nd_idx], n_back_adaptations[:, st_idx:nd_idx, :] = longtrace_adaptation.md_stim_adaptation(stims, \n",
    "                                                                                                    y_decay, \n",
    "                                                                                                    pref_range, \n",
    "                                                                                                    sharp_range)\n",
    "\n",
    "    # calculate adaptation weighted activations\n",
    "    adapted_activations = np.multiply(adaptations, activations)\n",
    "\n",
    "    return(activations, adaptations, adapted_activations, n_back_adaptations)\n",
    "\n",
    "\n",
    "def adaptation_forwardmodel(stim_df, pref_range, sharp_range, adaptations, adapted_activations):\n",
    "    \"\"\"forward model the adaptation, given the stimulus presented get the experienced amount of adaptation, activation etc.\n",
    "    input: stim_df: stimulus pandas dataframe with column ['frequencies_oct']\n",
    "           pref_range: range of prefferences - must match adapations grid\n",
    "           sharp_range: range of sharpnesses  - must match adapations grid\n",
    "           adapations: adaptations grid\n",
    "           adapted_activations: adapated activations grid\n",
    "    returns:\n",
    "           stim_df, with columns 'forward_adapation' and 'forward_adapted_activation'\n",
    "           \"\"\"\n",
    "\n",
    "    # -- prepair grid\n",
    "    # create a list of all indexes\n",
    "    all_idxs = np.arange(len(pref_range) * len(sharp_range))\n",
    "\n",
    "    # get grid of tuning pref and tuning sharpnesses\n",
    "    tunprefs, tunsharps = longtrace_adaptation.md_get_tuning(all_idxs, pref_range, sharp_range)\n",
    "\n",
    "    # -- tuning prefference grid possitioning\n",
    "    # get minimum indx\n",
    "    min_idx = np.argmin(np.abs(stim_df['frequencies_oct'].to_numpy()[:, np.newaxis] - pref_range), axis=1)\n",
    "\n",
    "    # get discrete closest value back\n",
    "    closest_val = pref_range[min_idx]\n",
    "\n",
    "    # from discrete get boolean array\n",
    "    pref_idx = closest_val == tunprefs[:, np.newaxis]\n",
    "\n",
    "    # -- tuning width positioning\n",
    "    # take one tw for now\n",
    "    what_tw = sharp_range[5]\n",
    "\n",
    "    # get bool array of where tw matches sellected tw\n",
    "    tw_idx = np.tile(tunsharps == what_tw, (len(stim_df['frequencies_oct']), 1)).T\n",
    "\n",
    "    # -- get logical intersection of the two\n",
    "    # combine the two\n",
    "    grid_idx = np.logical_and(pref_idx, tw_idx)\n",
    "    grid_idx = np.argmax(grid_idx, axis=0)\n",
    "    \n",
    "    # save in dataframe\n",
    "    stim_df['forward_adapation'] = adaptations[grid_idx, np.arange(len(grid_idx))]\n",
    "    stim_df['forward_adapted_activation'] = adapted_activations[grid_idx, np.arange(len(grid_idx))]\n",
    "    \n",
    "    return(stim_df)\n",
    "\n",
    "\n",
    "#drex\n",
    "def stims_export_mat(pp, input_dir, stim_df, pref_range):\n",
    "    \"\"\"export dataframe into mat file\"\"\"\n",
    "    stim_mat = {}\n",
    "\n",
    "    # get stimuli data\n",
    "    stim_mat['stims'] = stim_df.to_dict('list')\n",
    "\n",
    "    # aditionally get range data\n",
    "    stim_mat['oct_range'] = list(pref_range)\n",
    "    stim_mat['freq_range'] = list(2 ** pref_range)\n",
    "\n",
    "    scipy.io.savemat(join(input_dir, '{}_stimdf.mat'.format(pp, pp)), stim_mat)\n",
    "    return\n",
    "\n",
    "\n",
    "def stims_add_drex(pp, input_dir, stim_df):\n",
    "    \"\"\"load drex output mat, and append to dataframe\"\"\"\n",
    "    # load drex mat\n",
    "    mat = scipy.io.loadmat(join(input_dir,'{}_drexdf.mat'.format(pp, pp)))\n",
    "\n",
    "    # loop over frequencies\n",
    "    collumn_names = ['pred_prob_{:.3f}'.format(frq) for frq in mat['s_range'][0]]\n",
    "    temp_df = pd.DataFrame(columns=collumn_names)\n",
    "    for frq in range(len(mat['s_range'][0])):\n",
    "        cur_frq = mat['s_range'][0, frq]\n",
    "        temp_df['pred_prob_{:.3f}'.format(cur_frq)] = mat['prob_array'][frq]\n",
    "\n",
    "    # append surprisal and predictive probabilities\n",
    "    stim_df['surprisal'] = mat['surp_array'][0]\n",
    "    stim_df = pd.concat([stim_df, temp_df], axis=1)\n",
    "    return(stim_df)\n",
    "\n",
    "def stims_drex_forwardmodel(pp, input_dir, stim_df, drexfn_suffix='_drexdf.mat'):\n",
    "    \"\"\"forward model the adaptation, given the stimulus presented get the experienced amount of adaptation, activation etc.\n",
    "    input: pp: participant number\n",
    "           input_dir: what folder the drexdf.mat file is located\n",
    "           stim_df: stimulus pandas dataframe with column ['frequencies_oct']\n",
    "           drexfn_suffix(optional): suffix of the drexfilename\n",
    "    returns:\n",
    "           stim_df, with columns 'surprisal' and 'pred_prob'\n",
    "           \"\"\"\n",
    "    # load drex mat\n",
    "    mat = scipy.io.loadmat(join(input_dir,'{}{}'.format(pp, drexfn_suffix)))\n",
    "    tunprefs = mat['s_range'][0]\n",
    "\n",
    "    # get minimum indx\n",
    "    min_idx = np.argmin(np.abs(stim_df['frequencies_oct'].to_numpy()[:, np.newaxis] - tunprefs), axis=1)\n",
    "\n",
    "    # add surprisal and pred prob\n",
    "    stim_df['surprisal']  = mat['surp_array'][0]\n",
    "    stim_df['pred_prob']  = mat['prob_array'][min_idx, np.arange(len(min_idx))]\n",
    "\n",
    "    return(stim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1dff4e",
   "metadata": {},
   "source": [
    "# loading log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d2028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix 1 and 2, why are they wierd?\n",
    "\n",
    "ppz = [1, 2]\n",
    "\n",
    "# settings\n",
    "task = 0     # 0: main, 1: localizer\n",
    "loc_run = 1  # run 1 or run 2\n",
    "\n",
    "for pp in ppz:\n",
    "\n",
    "    # set behevioural directiories\n",
    "    stim_dir = f'/project/3018063.01/beh/stimuli/{pp}'\n",
    "    loud_dir = f'/project/3018063.01/beh/loudness/{pp}'\n",
    "    data_dir = f'/project/3018063.01/beh/data/{pp}'\n",
    "\n",
    "    #fns\n",
    "    sync_fn = f'MEG_sync_sub-{pp:03d}.mat'\n",
    "\n",
    "    # load sync files\n",
    "    sync_mat = scipy.io.loadmat(join(data_dir, sync_fn))\n",
    "    sync_val = sync_mat['MEG_sync']['mn'][0][0][0,0]\n",
    "    \n",
    "    \n",
    "    ## LOAD ACTUAL LOG DATA\n",
    "    \n",
    "    # get mat and stimuli struct\n",
    "    mat, stimuli = data_load(pp, data_dir, stim_dir)\n",
    "\n",
    "    # put in dataframe\n",
    "    df_beh = stims_load(mat, stimuli)\n",
    "    df_beh = sync_timing(df_beh, sync_val)\n",
    "    \n",
    "    \n",
    "    ## GAUSSIANS\n",
    "    \n",
    "    # settings\n",
    "    mat = scipy.io.loadmat(join(data_dir,'{}_settings_localizer.mat'.format(pp, pp)))\n",
    "    all_freqs = mat['cfg']['freq_array'][0][0][0,:]\n",
    "\n",
    "    # must match the tonotopy settings\n",
    "    tunsteps       = 10\n",
    "    freqstep       = 1\n",
    "    subsample      = np.arange(0,len(all_freqs), freqstep)\n",
    "    mustep         = np.diff(all_freqs[subsample])\n",
    "    muarray_bins   = all_freqs\n",
    "    muarray        = all_freqs[subsample]\n",
    "\n",
    "    # tuning sizes\n",
    "    fwhm           = np.linspace(1,(8), tunsteps)\n",
    "    octgrid        = fwhm / (2*np.sqrt(2*np.log(2)))\n",
    "    sigmagrid      = 2**octgrid\n",
    "\n",
    "    # set range of tunings and sharpnesses\n",
    "    pref_range  = muarray                # match t\n",
    "    sharp_range_fwhm = fwhm\n",
    "    sharp_range = octgrid                # check if correct, fwhm or sigma of gaussian?\n",
    "\n",
    "    \n",
    "    ## ALREADY ADD ADAPTATION\n",
    "    x_decay, y_decay = longtrace_adaptation.double_exp_decay_func(0.1399, 0.85, 0.0345, 6.82, [1, 10], 1)\n",
    "\n",
    "    activations, adaptations, adapted_activations, n_back_adaptations = run_adaptation(df_beh, \n",
    "                                                                                               pref_range, \n",
    "                                                                                               sharp_range, \n",
    "                                                                                               y_decay)\n",
    "    df_beh = adaptation_forwardmodel(df_beh, pref_range, sharp_range, adaptations, adapted_activations)\n",
    "\n",
    "    # cleanup collumns\n",
    "    del activations, adaptations, adapted_activations, n_back_adaptations\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## EXPORT MATFILE FOR DREX\n",
    "    stims_export_mat(pp, data_dir, df_beh, pref_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7ac3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
