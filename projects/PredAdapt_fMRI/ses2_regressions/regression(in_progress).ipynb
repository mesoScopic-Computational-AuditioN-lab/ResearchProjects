{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfaf921",
   "metadata": {},
   "source": [
    "### prepair modules and bases settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b198e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, log_loss\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import norm\n",
    "import scipy.io\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import contextlib\n",
    "from copy import deepcopy\n",
    "import imp \n",
    "import time \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd12a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorvhar/miniconda3/envs/predlis/lib/python3.8/site-packages/nilearn/glm/__init__.py:55: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  warn('The nilearn.glm module is experimental. '\n"
     ]
    }
   ],
   "source": [
    "# Add the directory containing your modules to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'ses2_modelstims')))\n",
    "\n",
    "# load local functions\n",
    "import stim_io\n",
    "import stim_io_plotting\n",
    "import vtc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb2256",
   "metadata": {},
   "source": [
    "## 1. Set up regresiion model\n",
    "Options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c36c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OVERALL OPTIONS ##\n",
    "save_predict = True           # save y_pred-y\n",
    "score_of_interest = 'score'\n",
    "\n",
    "SD_lim = 3                    # remove y x sd higher then mean\n",
    "remove_outliers = False       # if false dont remove sd outliers \n",
    "\n",
    "z_score_x = True              \n",
    "z_score_y = True              \n",
    "z_score_scope = 2             # 1:over all, 2:within run, 3:within block\n",
    "\n",
    "meanormedian = 'mean'         # mean makes varpart linear \n",
    "\n",
    "## OPTIONS ##\n",
    "ppz = [1,2]\n",
    "n_splitsz = [6,               # 12 runs > 10:2cross, 6 fold\n",
    "             6]               # splits used per pp (for variable length option) \n",
    "\n",
    "# all 3 models\n",
    "models = ['base',\n",
    "          'adaptation',\n",
    "          'prediction',\n",
    "          'base_U_adaptation',\n",
    "          'base_U_prediction',\n",
    "          'adaptation_U_prediction',\n",
    "          'base_U_adaptation_U_prediction']\n",
    "# if we want to use 2models: \n",
    "models=['base_U_adaptation', 'prediction', 'base_U_adaptation_U_prediction']\n",
    "\n",
    "## REGRESSORS IN MODELS ##\n",
    "model_regressors = {'base':       ['raw_acti', 'onoff'], \n",
    "                    'adaptation': ['raw_adapt' ],      # adaptation\n",
    "                    'prediction': ['pred_prob',   # voxelwise prior liklihood\n",
    "                                   'surprisal']   # global prior surprise\n",
    "                   } \n",
    "# if we want to add adapted activation\n",
    "# model_regressors['adaptation'] += ['adapt_activ']\n",
    "\n",
    "# set combination of regressors\n",
    "model_regressors.update({'base_U_adaptation':             model_regressors['base']+\n",
    "                                                          model_regressors['adaptation'],\n",
    "                        'base_U_prediction':              model_regressors['base']+\n",
    "                                                          model_regressors['prediction'], \n",
    "                        'adaptation_U_prediction':        model_regressors['adaptation']+\n",
    "                                                          model_regressors['prediction'], \n",
    "                        'base_U_adaptation_U_prediction': model_regressors['base']+\n",
    "                                                          model_regressors['adaptation']+\n",
    "                                                          model_regressors['prediction']})\n",
    "y_var = 'voxeltimecourse'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85b2a2",
   "metadata": {},
   "source": [
    "### loading input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15156b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs=lambda x: (x-x.mean(0)) /x.std(0)\n",
    "corr_column= lambda a,b: (zs(a)*zs(b)).mean(0)\n",
    "def zs_prior(x, prior_entr):\n",
    "    return((prior_entr-x.mean(0)) /x.std(0))\n",
    "\n",
    "def train_test_splits(df, n_splits, shuffle=True, random_state=123, group='run'):\n",
    "    \"\"\" Main function for getting an array of train test splits\n",
    "    \n",
    "    input: df        : pandas dataframe, to obtain 'group' from\n",
    "           n_splits  : number of train/test splits (k-folds)\n",
    "           shuffle   : (default true) whether to shuffle KFolds\n",
    "           random_state : (default 123) the random seed to use\n",
    "           group     : (default 'run') the group to use for splitting\n",
    "    \n",
    "    returns: training indexes : [n_splits * groups in training]\n",
    "             testing_indexes  : [n_splits * groups in testing]\"\"\"\n",
    "\n",
    "    # use sklearn tool for getting kfolds\n",
    "    kf = KFold(n_splits=n_splits, \n",
    "               shuffle=True,\n",
    "               random_state=123)\n",
    "\n",
    "    # get runs\n",
    "    runz = df['run'].unique()\n",
    "\n",
    "    # save empty list for train and test texts\n",
    "    train_indexes = np.empty((0, int(len(runz)-len(runz)/n_splits)), int)\n",
    "    test_indexes = np.empty((0, int(len(runz)/n_splits)), int)\n",
    "\n",
    "    # loop for text in folds\n",
    "    for train_index, test_index in kf.split(runz):\n",
    "        train_indexes = np.append(train_indexes, \n",
    "                                  np.array([runz[train_index]]), \n",
    "                                  axis=0)\n",
    "        test_indexes = np.append(test_indexes,\n",
    "                                 np.array([runz[test_index]]),\n",
    "                                 axis=0)\n",
    "        \n",
    "    # return train and test indexes\n",
    "    return(train_indexes, test_indexes)\n",
    "    \n",
    "    \n",
    "def model_fit(model, X_train,X_test,y_train,y_test, save_predict=False):\n",
    "    \"\"\"take the linear model, the train/test data and do scoring\n",
    "    input:  model:    input model type\n",
    "            X_train:  regressor input train data\n",
    "            X_test:   regressor input test data\n",
    "            y_train:  target train data\n",
    "            y_test:   target test data\n",
    "            save_predict:   save individual trail-by-trail predictions\n",
    "    output: return scores dictionary\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # fit model, get y_pred, model proba and nullmodel proba\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # get model score, classification report, confustion matrix and coefs/intercepts\n",
    "    scores['score'] = np.array([model.score(X_test, y_test)]) # place in array to make chunking easier\n",
    "    scores['raw_scores'] = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "    scores['coefs'] = model.coef_[:]\n",
    "    scores['intercepts'] = model.intercept_\n",
    "    scores['correlation'] = corr_column(y_test, y_pred)\n",
    "    \n",
    "    # save prediction scores if flagged\n",
    "    if save_predict:\n",
    "        scores['predict'] = {'y_pred': y_pred, 'y': y_test}\n",
    "    \n",
    "    # return cross validated scores\n",
    "    return(scores)\n",
    "\n",
    "\n",
    "def non_cv_fit(model, X, y, save_predict=False):\n",
    "    \"\"\"take the linear model, the train/test data and do scoring\n",
    "    input:  model:    input model type\n",
    "            X:        regressors\n",
    "            y:        target var\n",
    "            save_predict:   save individual trail-by-trail predictions\n",
    "    output: return scores dictionary\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # fit model, get y_pred, model proba and nullmodel proba\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    #scores['modelproba'] = model.predict_proba(X)\n",
    "    #scores['nullproba'] = pred_proba_null(y)\n",
    "    \n",
    "    # get model score, classification report, confustion matrix and coefs/intercepts\n",
    "    scores['score'] = model.score(X, y)\n",
    "    scores['raw_scores'] = r2_score(y, y_pred, multioutput='raw_values')\n",
    "    #scores['conf_mat'] = (confusion_matrix(y, y_pred).T / confusion_matrix(y, y_pred).sum(axis=1)).T\n",
    "    scores['coefs'] = model.coef_[:]\n",
    "    scores['intercepts'] = model.intercept_\n",
    "    scores['correlation'] = corr_column(y, y_pred)\n",
    "    \n",
    "    # save prediction scores if flagged\n",
    "    if save_predict:\n",
    "        scores['predict'] = {'y_pred': y_pred, 'y': y}\n",
    "    \n",
    "    # return scores    \n",
    "    return(scores)\n",
    "\n",
    "def zs_per_run(x, runs):\n",
    "    \"\"\"z-score x/y in dimension 1 given a list of runs of same length\n",
    "    e.g. if x = (2820, 5) then runs should be shape (2820) giving the indexes of runs\n",
    "    the resulting x is in this case zscored in the '2820' direction, devided in runs\"\"\"\n",
    "\n",
    "    # z-scoring across the zerod axis\n",
    "    zs=lambda i: (i-i.mean(0)) /i.std(0)\n",
    "\n",
    "    # z-score per run\n",
    "    for run in np.unique(runs):\n",
    "        x[runs == run] = zs(x[runs == run])\n",
    "    # get rid of nans and return\n",
    "    return(np.nan_to_num(x))\n",
    "\n",
    "def extract_sublist(lst, prefixes):\n",
    "    return [item for item in lst for prefix in prefixes if re.match(f\"^{prefix}\", item)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff5b61",
   "metadata": {},
   "source": [
    "### mask and vmp file loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1b7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MOSTLY EXAMPLE FUNCTION??\n",
    "\n",
    "import bvbabel\n",
    "import vtc\n",
    "\n",
    "mridat_dir = '/media/jorvhar/Data8T/MRIData/PreProc'\n",
    "vtc_dir = '/media/jorvhar/New Volume1/vtcs' # adviced to put vtc's on a (nvme) ssd while running analyses\n",
    "pp_dir = lambda pp, ses : f'S{pp:02d}_SES{ses}'\n",
    "betas_dir = 'Betas'\n",
    "\n",
    "# tonotopy and mask filenames\n",
    "tonotopy_vmp = 'prf_permutations.vmp'\n",
    "mask_fn = 'brainmask.msk'\n",
    "\n",
    "# chunking settings\n",
    "chunksize = 50000   # msk[0].shape[0]\n",
    "pp = 1\n",
    "ses = 2\n",
    "\n",
    "# fn lambda\n",
    "fn = lambda pp, ses, run : f'S{pp:02d}_SES{ses}_run{run}_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc'\n",
    "\n",
    "# create full path\n",
    "mskpath = join(mridat_dir, pp_dir(pp,1), mask_fn)\n",
    "vmppath = join(mridat_dir, pp_dir(pp,1), betas_dir, tonotopy_vmp)\n",
    "\n",
    "# load full mask and convert to indeces\n",
    "_, msk = bvbabel.msk.read_msk(mskpath)\n",
    "msk = np.where(msk)\n",
    "# devide the mask in chucks based on our chucksize\n",
    "chunked_msk = vtc.chunk_msk(msk, chunksize)\n",
    "\n",
    "# load vmp image\n",
    "vmp_head, vmp_img = bvbabel.vmp.read_vmp(vmppath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0a7b03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOP OVER TW AND TPREFS GET INDEXES OF PRF MAPPING\n",
    "\n",
    "\n",
    "# tonotopy and mask filenames\n",
    "mask_fn = 'brainmask.msk'\n",
    "# create full path\n",
    "mskpath = join(mridat_dir, pp_dir(pp,1), mask_fn)\n",
    "# load full mask and convert to indeces\n",
    "_, msk = bvbabel.msk.read_msk(mskpath)\n",
    "msk = np.where(msk)\n",
    "\n",
    "\n",
    "# tonotopy and mask filenames\n",
    "tonotopy_vmp = 'prf_permutations.vmp'\n",
    "# load vmp image\n",
    "score_vmp_head, vmp_placeholder = bvbabel.vmp.read_vmp(join(mridat_dir, pp_dir(pp,1), betas_dir, tonotopy_vmp))\n",
    "score_vmp_full = np.zeros((list(vmp_placeholder.shape[:-1]) + [3 * 4]))\n",
    "score_vmp_head['NrOfSubMaps'] = 2\n",
    "score_vmp_head['Map'] = []\n",
    "score_vmp = np.zeros(vmp_placeholder.shape[:3])\n",
    "\n",
    "# load tonotopy vmp\n",
    "vmp_df = pd.DataFrame(vmp_img[msk])\n",
    "\n",
    "# create grid and do full loop\n",
    "for tpref, tw in itertools.product(pref_range, sharp_range):\n",
    "\n",
    "    # get grid position indexes for tuning pref and tw\n",
    "    grid_idx = vmp_df.loc[np.isclose(vmp_df[0], tpref, rtol=1e-3) & \n",
    "                          np.isclose(vmp_df[1], tw, rtol=1e-3)].index\n",
    "    # this is a linear index\n",
    "    \n",
    "    # check if any boxels in gridposition\n",
    "    if grid_idx.empty == False:\n",
    "        \n",
    "        # use these grid positions to get a chuck of the mask\n",
    "        msk_chunk = [i[grid_idx] for i in msk]\n",
    "        \n",
    "        pred = tr_df[f'pred_prob_{tpref:.3f}_convolved'].iloc[100]\n",
    "        actv = tr_df[f'raw_acti_{tpref:.3f}_{tw:.3f}_convolved'].iloc[100]\n",
    "        score_vmp[msk_chunk] = pred\n",
    "    \n",
    "    \n",
    "#     score_vmp_full[:,:,:,val] = score_vmp\n",
    "    \n",
    "    \n",
    "  ## SETUP FOR ALL, FIRST TRY WITH ONE...\n",
    "\n",
    "#     idxz = [1775, 1782, 1790, 1797]\n",
    "#     for idx in range(len(idxz)):\n",
    "        \n",
    "#         # get current tw tpref expected\n",
    "#         pred = tr_df[f'pred_prob_{tpref:.3f}_convolved'].iloc[idxz[idx]]\n",
    "#         actv = tr_df[f'raw_acti_{tpref:.3f}_{tw:.3f}_convolved'].iloc[idxz[idx]]\n",
    "#         adpt = tr_df[f'raw_adapt_{tpref:.3f}_{tw:.3f}_convolved'].iloc[idxz[idx]]\n",
    "\n",
    "#         #full map\n",
    "#         valz = [pred, actv, adpt]\n",
    "#         for val in range(len(valz)):\n",
    "#             score_vmp[grid_idx] = valz[val]\n",
    "#             score_vmp_full[:,:,:,val] = score_vmp\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #score_vmp_head['Map'].append(set_map('pred', mapthreshold=0, mapupperthreshold=10))\n",
    "\n",
    "    #bvbabel.vmp.write_vmp('/media/jorvhar/Data1/MRIData/PreProc/S0{}_SES1/Betas/map2023-1.vmp'.format(pp),score_vmp_head, score_vmp_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THERE SEEMS TO BE AN ERROR WITH THE GETHERING OF LOCATIONS, DOUBLE CHECK IF THIS ALL IS WORKING CORRECTLY\n",
    "# seems that there is only one predictior for the whole field, which isnt right, make sure this is fixed for eventual analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "57f00b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_map(mapname, mapthreshold=1.65, mapupperthreshold=8.0):\n",
    "    FDRTableInfo = np.array([], dtype=np.float64)\n",
    "    FDRTableInfo.shape = (0,3)\n",
    "    returnmap = {'TypeOfMap': 1,\n",
    "     'MapThreshold': mapthreshold,\n",
    "     'UpperThreshold': mapupperthreshold,\n",
    "     'MapName': mapname,\n",
    "     'RGB positive min': np.array([255,   0,   0], dtype=np.uint8),\n",
    "     'RGB positive max': np.array([255, 255,   0], dtype=np.uint8),\n",
    "     'RGB negative min': np.array([255,   0, 255], dtype=np.uint8),\n",
    "     'RGB negative max': np.array([  0,   0, 255], dtype=np.uint8),\n",
    "     'UseVMPColor': 0,\n",
    "     'LUTFileName': '<default>',\n",
    "     'TransparentColorFactor': 1.0,\n",
    "     'ClusterSizeThreshold': 50,\n",
    "     'EnableClusterSizeThreshold': 0,\n",
    "     'ShowValuesAboveUpperThreshold': 1,\n",
    "     'DF1': 249,\n",
    "     'DF2': 1,\n",
    "     'ShowPosNegValues': 3,\n",
    "     'NrOfUsedVoxels': 45555,\n",
    "     'SizeOfFDRTable': 0,\n",
    "     'FDRTableInfo': FDRTableInfo,\n",
    "     'UseFDRTableIndex': 0}\n",
    "    return(returnmap)\n",
    "\n",
    "# full map\n",
    "score_vmp_full[:,:,:,0] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('pred', mapthreshold=0, mapupperthreshold=10))\n",
    "\n",
    "bvbabel.vmp.write_vmp('/media/jorvhar/Data8T/MRIData/PreProc/S0{}_SES1/Betas/test-1.vmp'.format(pp),score_vmp_head, score_vmp_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf150a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66a8a933",
   "metadata": {},
   "source": [
    "### reconstruction of image\n",
    "(for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1b652d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: (50000, 2350)\t run_nr shape: (2350,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd7f32f2850>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZBklEQVR4nO3da5Ad5X3n8e/Tl3OZq2Z0HXQXEo+5WjiEuExM8DqxsTcx4FQR2JSNHco2FUgqm1Rt2Wxq7dq8cWWNXaR2TW1wKHCVjU0uLlMuKmCT2thxBYzBxFwfkIRAGiQNmvvMOXPO6cu+6FYypiUj6cyZoxG/T5Vq+jzdc/rpOdJP3U/3PH+TpikiIot53e6AiJx5FAwiUqBgEJECBYOIFCgYRKRAwSAiBUGn3thaezVwJ+ADX3POfbFT+xKRpWU68RyDtdYHXgJ+CzgIPAHc6Jx7fsl3JiJLrlOXEpcDe5xz+5xzTeBbwDUd2peILLFOXUpsBA4sen0Q+LUTbXzuzl1pFOkJTJHlVCn7R51za4+3rmNjDKciilIOjta63Q2Rt5WdO/pfPdG6Tl1KjAKbF73elLeJyArQqTOGJ4Bd1trtZIFwA/BfOrQvEVliHTljcM5FwG3Aw8ALwAPOuec6sS8RWXodG2Nwzj0EPNSp9xeRztGTjyJSoGAQkQIFg4gUKBhEpEDBICIFCgYRKVAwiEiBgkFEChQMIlKgYBCRAgWDiBQoGESkQMEgIgUKBhEpUDCISIGCQUQKzojJYKWzLl69Dd94+Hg004hnxvd3u0tyhjvtYLDWbga+DqwHUuCvnXN3Wmu/AHwKeCPf9PZ8NidZZnZoE1W/xH8qbaYHQ4Bh0sTUVjWYas4zXpvpdhflDNXOGUME/Jlz7ilrbT/wpLX2+/m6rzjnvtR+995+fM8n8HyiJCZO4hNuZ4xhsNxLSlaPI/QCjtamAVjXu4qyH3JZdRP9JiAlpTfxGI4NQ17Ah3p38nRpnGeSV5lemF+W45KV5bSDwTl3CDiUL89aa18gKzQjp6Ealin5AYHnU/ZD0jTFGMP68ip2llbTT8BL0RSPj7/Eht4h6lGTkeoQaZqSkLIm7OdwuY+yF3JxeQMDJqCKR4OUFik+hnVRTJmEjcZnsLwOf9DjxWCUsfkpOlGqUFauJRljsNZuAy4FHgeuAG6z1n4c+CnZWcXkUuznbFUOSqytDlLxQ5pJRJ9fYXt5DZeaAT7QrHPhh2r4I8O8eHcvtw3vYCToZzJZYI3XgwEiEka8KteY9WyIUnoWEgJS6sZjwTMA9MVZKJRJWF+qM7RQJqysZctAP646TjONmGrNM9daoC+s0B9UidOE2ahOPWoSej6tJCYlZa65QCNqdveHJh3VdjBYa/uAvwf+xDk3Y629C/gLsnGHvwDuAP6g3f2crUp+yEjvEFW/xHzUYDDsYXd5hA82K7x38yEGr+jD27yZdGaOVUN13jdzDs+lM1zlr2P3QkLd85j1DEPNhPN7JxnaXKM2HTI9XaUR+VT8iEYUcMCrcNAPGY5TaEADj82RYVta4YPpRiZ8w95yxHQaYdMy5zZT5n3D3krKtEkYSD3GTcRMGvF8c4xX5o4w26iTpEm3f4TSAW0Fg7U2JAuFbzjn/gHAOXdk0fq7ge+11cOz3LqeQTaVV1PxAoKSxwXeIL+5kGBHjlAeimjumyZ9cYrJV6v8eHodrwd1zjP9XGemWbWpzisHh+hLAgZNRE9vEy9MSGKPyVaZgJThap2gmUCjQstAy8A0AWOBz4EgYTjxSIEpL+GCVsDWKGXArxFjaMY+O5KE4b46npeyZ3qQZ8tVwtJ6Sv0B+/0xJhfmaMXRLz1Gz3is6Rkg8HxKXkDVLxEYnyiNmWjOMdusU2suLM8PXE5KO3clDPA3wAvOuS8vah/Jxx8ArgOeba+LZ591vatYVeqlmURsKq/m0nANl7QCLmGOLe8YpbQ+oHkkYub1Cp5JqQy0SBODl6YMmoBtkc/QSI2o4TNPFgpDPXXqtZCZ6QozjTIAw9U6fasaeEHKRWMJ/bMDHPV9ap5Hw4PXaPCKl7KJMpc2DbY0TSP12Zf2cjg09CawPoqJZj0OeSWeqMa8HE9RT1r4xmNjdTVDpT6O1KeYWpg77rGGfsCOgQ1cUd3CWkqsTTy2tRLWs0ALjx/3l/lB8gZPTu5lrllfzo9Bfol2zhiuAD4GPGOtfTpvux240Vq7m+xSYj/wmTb2cdbZMrCOP+y9iN+I5tif9jDqeVxab2DPO0x1q0eweS0kKdHkUTyTYryUuOkRlmJ2JAu8klY45CeMH+mjWm1SNx49qSEMY6ZnK7yW9FDzDGvjmP6BBtWRGOPBYFJn3UJIuVVizCvRAvpNQEzK1fUWO7ZMMHaon8m4TJWE9ZHHjG/4t4rHflIOJ5MQZ+MZs0mDVhLR71d5f2kTtZ6Ev5t6hrH5qV841tAPeMeqTfxueTs9qaEvgXVRwnDaZLCvwepNc5xb91k7eg7r1vTw+Nx+XpsZ68rnIr+onbsS/wKY46zSMwvHcU7/alaX+vlyupHLPnwUE3hs/Ok081Nl+rcukLQMYz8tUX5uiupwRNzwMF52pyCJDUlqKHkxg4lhIm8f3lZj/b/1MkGJvrkKUeLxYtmwITI0MbSaPmkzpTnrUZ8NOWf7NDtG4Gf/vJb9psQ7WyGr44QL33WQxqRPnBhWBw2SFKLEY7pVYtrzCY1hq99HCY/D6QJTcZ0N4SC/kw7zG+FEdoCrLuar8z/69+Mt+SEXDm3h2tIWWqTEwLQHBB5hK6A518dLbpC1NHjvwDjviT32BufzR/0J9biJwZCkCa0kxjOGnqBMQkqcJNSihi49OkxPPnaAMQbPeJSDkNDzCb2A/xteyHt/bw6ok0xHUPLp3WmoTNdYeMNndqKCHyRU17QI+g3xGMzPlvH9hP7hBdIEmolPmD/EfrRRYWu/x9bNk3BgCM9LiOOAr809y1eD8xkwLTw/oTHps2//asYo8Z6h1wl3rqH6o5jIwFCcndIffG4Vc82QkhezEPvMpwEhCX0m4uIGXIxPzXg8Xza8mDRYiJtsDtfxHqYZ3jjPUy+OcKA8TzUsU281CP2A3cPbudlsIo5h3IOGyf4XGfNTIOAdrQUSfPb4VSrzMYODdTY2atxhLuKFsqEnNcyYhCO0SIFfjcp4QN3AY36N/zf7MofmJnSbtUMUDEss9AMGyj2MVIa4tHIOWyizs2W4aOQw6bxPNN6gNQVeqUlU82jVQpoLPrV6SCmMCfoMwYYe4vl54thQXygTlmMqvS0GKg02LJQJ8EgxtCZT0sQQpR7zrRILqc9dwfms9hcI/GwQMm55DJQbTC6EPLbnHM4fm2QqGaSUwtHAY7AV8HqzwpzvsS6KiDC0jCFMPUhhjWmwbvUcc7MVXksG8DD4xmOWiJ9Fg/S5fl4qG3aZPpqrz+fhw0+zY2ADHw02MZY/fJUY6EsMkYEWKS0DMQYPeMOHH9BLMtdL7MOgMdhmQjlJ6CciNClHKTHpw68E02y6ZJoP7qvwh81dfLY6w+PjL73l4KecOgXDEhqs9HLxwFYuDIe5shGyvVVjIk4ISajNlvCfXSDszbatH80CwfdTTH4WUFsImdxTZqCWPY0YBAlH6mUW3vDZaGbYsGuGDczQmvUJexOCAZh7tcxhr4RHyrTvcWFco7fa4shcDy7qpzUD6+OIQVrcXzb8/oEXqAQhfxn8Gr1JSr/fYshrMN0qMWFCWia7OhwNPVoGaq0q00dLzBuPeimll5CKV2I+bfFSkDDke9RMQmpSYhJ8zyc0PqNexFTaYpUJ2ZgEtEzKuEkoY1gbGyZNSGyy3+JbMFBJDYMxDMcpQ0lMC8MsARu8Bbb6c/Q1q4xGvUz9pMzFV7zBxluu5ZEdl/Kfr/o8/zz2vG6bLjEFQxuMMZT8kJIf4BnD3b2/yua0RhAvEJRreF7KqrBO/+oGfjkhaRlmx8rMTldoRh6VUsTAqgUCk1AuxfQGTXqHG3gVQ9pM8f2EaeMzbgKqExEDWxuUtvYRvD5PPJ/SOOoxNVeh6UHTePzXyR/z8q9sJW54vDbXz1OlhGeSKWZY4JJwDZ4xfGTdbq5t9jIUtRipzlOpRESRhzEprWZ2lvBaEHLYS1ib38rcWwoY9WIMsIMeSqHHZNLgZeYZNiUCY+hJfaom5KKhLXw83M5YmhCbAA+YNAk1kzCU+gwlhr4ke5A7TGFDlDLjGRoGUgMzvqFlAgzZ6HUjreK3oOUZwjSlH3j5sWHMY49w3lV/y/0XxlyT7OKn43t+6SPkcmoUDKehGpZJ0pRNfav5SO8uPlyPGS43ONqIOBxXiROD30wpkzDkNzAGSpWIVtPn8EQ/h0yJMIX+esREvcq4CZnwPd4RL7D2gjpe1WP+CESRT0+aMGN8Rls9zP0kZOiZBZqtIepxQJwaRv0SM75hMM5O26MFj/EjfUz4PlVSzvF6mIxr7I1nuDFdy4xXYtyHNUnKQjOgp7fJ7EyVPfQwXjK0DBw12T+wnhQqaUo5MRjPEAJrE5+WX+ZQOs+B5gSDQQ/nBUOMENJjAozJbnOeg8eUZ5gyMeO0IIUQg+95zIUQYKikhgSIDTRISQzEwJyf4AH9eAT5Ni0DPanHobTCSCthZ3mW6Rc8Sn0p3/+jLVz5Vy2ePrqvS38jzj7mTBi82bptZ3pwtNbtbryl4Wo/SZriex7v7N/KR1nL+a0Gh70Sc57htvEf6npXVoydO/qfdM5ddrx1OmM4BRP12X9f/qfaM/xTF/si0kmawUlEChQMIlKgYBCRAgWDiBQoGESkQMEgIgUKBhEpUDCISIGCQUQKlmIy2P3ALNlj7pFz7jJr7TDwbWAb2SxO12umaJGVY6nOGN7nnNu96LnrzwKPOud2AY/mr0VkhejUpcQ1wH358n3AtR3aj4h0wFIEQwo8Yq190lr76bxt/aKZog+T1bcUkRViKYLh151z7wI+BNxqrb1y8UrnXAp0/3e7ReSktR0MzrnR/OsY8B3gcuCItXYEsjoTgOYEF1lB2goGa21vXukaa20v8AGyAjMPAjflm90EfLed/YjI8mr3duV64DvW2mPv9U3n3D9aa58AHrDW3gy8Clzf5n5EZBm1FQzOuX3AO4/TPg68v533FpHu0ZOPIlKgYBCRAgWDiBQoGESkQMEgIgUKBhEpUDCISIGCQUQKFAwiUqBgEJECBYOIFCgYRKRAwSAiBQoGESlQMIhIgYJBRAoUDCJScNozONlsPrdvL2raAfwPYBXwKeCNvP1259xDp7sfEVl+px0MzjkH7Aaw1vrAKNks0Z8EvuKc+9JSdFBElt9SXUq8H9jrnHt1id5PRLpoqYLhBuD+Ra9vs9b+3Fp7j7V2aIn2ISLLpO1gsNaWgI8Af5s33QWcS3aZcQi4o919iMjyareuBGSl6Z5yzh0BOPYVwFp7N/C9JdiHiCyjpbiUuJFFlxHHStPlriOrTCUiK0hbZwx5WbrfAj6zqPkvrbW7yQrZ7n/TOhFZAdqtRDUPrH5T28fa6pGIdJ2efBSRAgWDiBQoGESkQMEgIgUKBhEpUDCISIGCQUQKFAwiUqBgEJECBYOIFCgYRKRAwSAiBQoGESlQMIhIgYJBRAoUDCJScFITtVhr7wF+Gxhzzl2Utw2TFZzZRjZT0/XOuUlrrQHuBD4M1IBPOOeeWvqui0innOwZw73A1W9q+yzwqHNuF/Bo/hqyyWF35X8+TTZrtIisICcVDM65HwITb2q+BrgvX74PuHZR+9edc6lz7jFg1ZsmiBWRM1w7YwzrnXOH8uXDwPp8eSNwYNF2B/M2EVkhlmTw0TmXks0KLSJngXaC4cixS4T861jePgpsXrTdprxNRFaIdoLhQeCmfPkm4LuL2j9urTXW2ncD04suOURkBTjZ25X3A1cBa6y1B4HPA18EHrDW3gy8Clyfb/4Q2a3KPWS3Kz+5xH0WkQ4zadr9oYGt23amB0dr3e6GyNvKzh39TzrnLjveOj35KCIFCgYRKVAwiEiBgkFEChQMIlKgYBCRAgWDiBQoGESkQMEgIgUKBhEpUDCISIGCQUQKFAwiUqBgEJECBYOIFCgYRKRAwSAiBW85tdsJqlD9L+B3gCawF/ikc27KWrsNeAFw+bc/5py7pRMdF5HOOZkzhnspVqH6PnCRc+4S4CXgc4vW7XXO7c7/KBREVqC3DIbjVaFyzj3inIvyl4+RTREvImeJk5ol+i38AVlx22O2W2t/BswAf+6c+9ES7ENEllFbg4/W2v8ORMA38qZDwBbn3KXAnwLftNYOtNdFEVlupx0M1tpPkA1K/n5eog7nXMM5N54vP0k2MHneEvRTRJbRaQWDtfZq4L8BH3HO1Ra1r7XW+vnyDmAXsG8pOioiy+dkblcerwrV54Ay8H1rLfzHbckrgf9prW0BCXCLc27iuG8sImcsVaISeZtSJSoROSUKBhEpUDCISIGCQUQKFAwiUqBgEJECBYOIFCgYRKRAwSAiBQoGESlQMIhIgYJBRAoUDCJSoGAQkQIFg4gUKBhEpOB0C858AfgU8Ea+2e3OuYfydZ8DbgZi4I+dcw93oN8i0kEnM338vcD/Br7+pvavOOe+tLjBWnsBcANwIXAO8ANr7XnOuXgJ+ioiy+S0Cs78EtcA38pni34F2ANc3kb/RKQL2hljuM1a+3Nr7T3W2qG8bSNwYNE2B/M2EVlBTjcY7gLOBXaTFZm5Y6k6JCLdd1ol6pxzR44tW2vvBr6XvxwFNi/adFPeJiIryOkWnBlZ9PI64Nl8+UHgBmtt2Vq7nazgzE/a66KILLfTLThzlbV2N5AC+4HPADjnnrPWPgA8T1bT8lbdkRBZeVRwRuRtSgVnROSUKBhEpEDBICIFCgYRKVAwiEiBgkFEChQMIlKgYBCRAgWDiBQoGESkQMEgIgUKBhEpUDCISIGCQUQKFAwiUqBgEJECBYOIFJxuJapvAzbfZBUw5Zzbba3dBrwAuHzdY865W5a60yLSWadVico593vHlq21dwDTi7bf65zbvUT9E5EuaKsSlbXWANcD9y9xv0Ski06rrsQi7wWOOOdeXtS23Vr7M2AG+HPn3I/a3IeILLN2Bx9v5BfPFg4BW5xzlwJ/CnzTWjvQ5j5EZJmddjBYawPgo8C3j7XlxWzH8+Ungb3Aee12UkSWVztnDL8JvOicO3iswVq71lrr58s7yCpR7WuviyKy3N4yGPJKVP+aLdqD1tqb81U3UBx0vBL4ubX2aeDvgFucc8cduBSRM5cqUYm8TakSlYicEgWDiBQoGESkQMEgIgUKBhEpUDCISIGCQUQKFAwiUqBgEJECBYOIFCgYRKRAwSAiBQoGESlQMIhIgYJBRAoUDCJScDIFZzaT1ZRYD6TAXzvn7rTWDpPN97gN2A9c75ybzKeUvxP4MFADPuGce6oz3ReRTjiZM4YI+DPn3AXAu4FbrbUXAJ8FHnXO7QIezV8DfIhsrsddwKeBu5a81yLSUSdTcObQsf/xnXOzZCXoNgLXAPflm90HXJsvXwN83TmXOuceA1ZZa0eWuuMi0jmnNMaQ16a8FHgcWO+cO5SvOkx2qQFZaBxY9G0H8zYRWSFOOhistX3A3wN/4pybWbzOOZeSjT+IyFngpILBWhuShcI3nHP/kDcfOXaJkH8dy9tHgc2Lvn1T3iYiK8TJ1JUwwN8ALzjnvrxo1YPATfnyTcB3F7V/3FprrLXvBqYXXXKIyApwMkVtrwA+BjyTF5IBuB34IvBAXoDmVbKq1wAPkd2q3EN2u/KTS9lhEem8twwG59y/AOYEq99/nO1T4NY2+yUiXaQnH0WkQMEgIgUKBhEpUDCISIGCQUQKFAwiUqBgEJECBYOIFJzMk48dVyn7R3fu6H+12/0QeZvZeqIVJk31S5Ei8ot0KSEiBQoGESlQMIhIgYJBRAoUDCJS0PXbldbaq8nqUPjA15xzX+xyl06JtXY/MAvEQOScu+xENTe61cdfxlp7D/DbwJhz7qK8bUXWDDnBsXwB+BTwRr7Z7c65h/J1nwNuJvvs/tg59/Cyd/o4zoRaLl09Y7DW+sD/IatFcQFwY16zYqV5n3Nut3Pusvz1iWpunInuBa5+U9tKrRlyL8VjAfhK/vnsXhQKFwA3ABfm3/PV/O/jmaDrtVy6fSlxObDHObfPOdcEvkVWl2KlO1HNjTOOc+6HwMSbmldkzZATHMuJXAN8yznXcM69QjYV4eUd69wpOBNquXQ7GM6GGhQp8Ii19klr7afzthPV3FgpzraaIbdZa39urb3HWjuUt62IY+lWLZduB8PZ4Nedc+8iO5271Vp75eKVK73mxkrvP9lp9bnAbuAQcEdXe3MKulnLpdvBsOJrUDjnRvOvY8B3yE5HT1RzY6U4a2qGOOeOOOdi51wC3M1/XC6c0cfS7Vou3Q6GJ4Bd1trt1toS2WDQg13u00mz1vZaa/uPLQMfAJ7lxDU3VoqzpmbIm661ryP7fCA7lhustWVr7XaygbufLHf/judMqOXS1duVzrnIWnsb8DDZ7cp7nHPPdbNPp2g98B1rLWQ/y2865/7RWvsEx6+5ccax1t4PXAWssdYeBD7PCq0ZcoJjucpau5vstHs/8BkA59xz1toHgOfJ7gLc6pyLu9Dt4+l6LRf9dqWIFHT7UkJEzkAKBhEpUDCISIGCQUQKFAwiUqBgEJECBYOIFCgYRKTg/wPvtiy0jw9KvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get vtc filenames\n",
    "runz = [1,2,3,4,5,6,7,8,9,10]\n",
    "vtc_fns = [join(mridat_dir, pp_dir(pp,ses), fn(pp,ses,run)) for run in runz]\n",
    "\n",
    "# load vtc chunks\n",
    "y, run_nr = stim_io.load_vtc_chunk_runs(vtc_fns, chunked_msk[0])\n",
    "print(f'y shape: {y.shape}\\t run_nr shape: {run_nr.shape}')\n",
    "\n",
    "# senity check to display a chunk\n",
    "n_img = stim_io.reconstruct_vtc(y[:,run_nr==5], chunked_msk[0], \n",
    "                                vtc_for_header=vtc_fns[0]) # or None\n",
    "plt.imshow(n_img[:,:,40,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ccb16179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frequencies                                    NaN\n",
       "frequencies_oct                                NaN\n",
       "timing                                2.518451e+06\n",
       "closest_volume_rel                    1.510000e+02\n",
       "closest_volume_abs                    1.796000e+03\n",
       "                                          ...     \n",
       "adapt_activ_12.469_3.397_convolved             NaN\n",
       "adapt_activ_12.489_3.397_convolved             NaN\n",
       "adapt_activ_12.510_3.397_convolved             NaN\n",
       "adapt_activ_12.530_3.397_convolved             NaN\n",
       "adapt_activ_12.551_3.397_convolved             NaN\n",
       "Name: 13217, Length: 22340, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df.iloc[1797]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7801540d",
   "metadata": {},
   "source": [
    "## Doing the regressions\n",
    "(testing for single tpref and tw - chunked regressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f122f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick settings\n",
    "# n_splits = 6  #6\n",
    "# tpref = 9.9228\n",
    "# tw = 0.755\n",
    "# convolved = True\n",
    "\n",
    "# # get vtc filenames and settings\n",
    "# runz = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "# save_predict = False\n",
    "\n",
    "# # set modeltype\n",
    "# modeltype = LinearRegression() #can be LinearRegression (ols), Ridge(alpha=..), Lasso(alpha=..)  etc.\n",
    "# key_ai = ['raw_scores', 'coefs', 'intercepts', 'correlation'] # what keys to median and mean across folds\n",
    "\n",
    "\n",
    "# ## --- DEFINING TEST TRAIN SPLIT ---\n",
    "\n",
    "# # get test train splits per run\n",
    "# train_matrix, test_matrix = train_test_splits(stim_df, n_splits)\n",
    "\n",
    "\n",
    "# ## --- BASED ON TUNING PREF AND TW LOAD DESIRED COLUMNS OUT OF DF ---\n",
    "\n",
    "# # load (all) xnames\n",
    "# col_names = stim_io.get_tw_collumns(tr_df, tpref, tw, convolved=convolved)\n",
    "\n",
    "# # load voxeltimecourse filenames\n",
    "# vtc_fns = [join(mridat_dir, pp_dir(pp,ses), fn(pp,ses,run)) for run in runz]\n",
    "\n",
    "# # predefine dictionaries for saving regression results\n",
    "# scores = {}\n",
    "\n",
    "\n",
    "# # --- LOOP OVER CHUCKS TO MANAGE MEMORY ---\n",
    "# for curchunk in range(len(chunked_msk)):\n",
    "    \n",
    "#     # load vtc for chunk\n",
    "#     y, run_nr = stim_io.load_vtc_chunk_runs(vtc_fns, chunked_msk[curchunk])\n",
    "#     y = y.transpose() # transpose to make k-fold splits simpler\n",
    "\n",
    "    \n",
    "# # --- LOOP OVER ALL MODELS FOR DOING SET THEORY --- \n",
    "#     for model in models:\n",
    "\n",
    "#         # get X for this model \n",
    "#         col_regressors = extract_sublist(col_names, model_regressors[model])\n",
    "#         X = tr_df[col_regressors].to_numpy()\n",
    "#         print(f'{model}:\\n\\t\\t{extract_sublist(col_names, model_regressors[model])}\\n')\n",
    "\n",
    "#         # (re)predefine dictionary for storing this models all folds\n",
    "#         nscore = {}\n",
    "        \n",
    "        \n",
    "# ### --- RUN SCRIPT TO DO KFOLDED REGRESSION, AND PARSE OUTPUT IN MEANINGFULL WAY\n",
    "#         # get cross validated scores based on previously defined test/train splits\n",
    "#         for fold in range(len(train_matrix)):\n",
    "#             # save indexes for text number in array\n",
    "#             train_idx = np.argwhere(np.in1d(run_nr, train_matrix[fold])).flatten()\n",
    "#             test_idx = np.argwhere(np.in1d(run_nr, test_matrix[fold])).flatten()\n",
    "\n",
    "#             # select train and test sets for fold\n",
    "#             X_train, X_test = X[train_idx], X[test_idx]\n",
    "#             y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "#             # do the regression\n",
    "#             nscore[fold+1] = model_fit(modeltype, \n",
    "#                                        X_train,\n",
    "#                                        X_test,\n",
    "#                                        y_train,\n",
    "#                                        y_test,\n",
    "#                                        save_predict=save_predict)\n",
    "            \n",
    "#         # check if we update previous chunk or initate dict using this one\n",
    "#         if model not in scores:\n",
    "#             scores[model] = nscore\n",
    "#         else:\n",
    "#             # combine all the folds into one dictionary - aditionally append chunks\n",
    "#             for fold in range(len(train_matrix)):\n",
    "#                 scores[model][fold+1] = {key : np.concatenate((scores[model][fold+1][key], \n",
    "#                                                                nscore[fold+1][key])) for key in nscore[fold+1]}\n",
    "                \n",
    "#         # store median and mean across folds\n",
    "#         for k in key_ai:\n",
    "#             cv_scores = {'median':  np.median(np.array([scores[model][fold+1][k] for \n",
    "#                                                         fold in range(len(train_matrix))]), axis=0),\n",
    "#                          'mean':   np.nanmean(np.array([scores[model][fold+1][k] for \n",
    "#                                                         fold in range(len(train_matrix))]), axis=0)}\n",
    "#             scores[model][k] = cv_scores\n",
    "            \n",
    "            \n",
    "# ### --- DO ANOTHER REGRESSION WITHOUT CROSS VALIDATION, TO VALIDATE RESULTS\n",
    "#         # get non-crossvalidated scores\n",
    "#         scores[model]['non-cv'] = non_cv_fit(modeltype, \n",
    "#                                                 X,\n",
    "#                                                 y,\n",
    "#                                                 save_predict=save_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb324d58",
   "metadata": {},
   "source": [
    "## Full regression\n",
    "- using tpref and tw from vmp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab113905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run1_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run1_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n",
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run2_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run2_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n",
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run3_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run3_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n",
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run4_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run4_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n",
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run5_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run5_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n",
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run6_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run6_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n",
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run7_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run7_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n",
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run8_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run8_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n",
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run9_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run9_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n",
      "Copied /media/jorvhar/Data8T/MRIData/PreProc/S03_SES2/S03_SES2_run10_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc to /media/jorvhar/New Volume1/vtcs/S03_SES2_run10_FMR_SCSTBL_3DMAS_THPGLMF7c_TOPUP.vtc\n"
     ]
    }
   ],
   "source": [
    "origin_fns = [join(mridat_dir, pp_dir(pp, ses), fn(pp,ses,run)) for run in runz]\n",
    "vtc_fns = [join(vtc_dir, fn(pp,ses,run)) for run in runz]\n",
    "\n",
    "# copy to ssd for efficient chunk processing\n",
    "stim_io.copy_files(origin_fns, vtc_fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2daa67",
   "metadata": {},
   "source": [
    "then run the full regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82fe6e92",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'base_U_adaptation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 129>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m key_ai:\n\u001b[0;32m--> 131\u001b[0m         cv_scores \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m:  np\u001b[38;5;241m.\u001b[39mmedian(np\u001b[38;5;241m.\u001b[39marray([scores[model][fold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][k] \u001b[38;5;28;01mfor\u001b[39;00m \n\u001b[1;32m    132\u001b[0m                                                     fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_matrix))]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    133\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:   np\u001b[38;5;241m.\u001b[39mnanmean(np\u001b[38;5;241m.\u001b[39marray([scores[model][fold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][k] \u001b[38;5;28;01mfor\u001b[39;00m \n\u001b[1;32m    134\u001b[0m                                                     fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_matrix))]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)}\n\u001b[1;32m    135\u001b[0m         scores[model][k] \u001b[38;5;241m=\u001b[39m cv_scores\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# save indexes\u001b[39;00m\n",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m key_ai:\n\u001b[0;32m--> 131\u001b[0m         cv_scores \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m:  np\u001b[38;5;241m.\u001b[39mmedian(np\u001b[38;5;241m.\u001b[39marray([\u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m[fold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][k] \u001b[38;5;28;01mfor\u001b[39;00m \n\u001b[1;32m    132\u001b[0m                                                     fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_matrix))]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    133\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:   np\u001b[38;5;241m.\u001b[39mnanmean(np\u001b[38;5;241m.\u001b[39marray([scores[model][fold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][k] \u001b[38;5;28;01mfor\u001b[39;00m \n\u001b[1;32m    134\u001b[0m                                                     fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_matrix))]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)}\n\u001b[1;32m    135\u001b[0m         scores[model][k] \u001b[38;5;241m=\u001b[39m cv_scores\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# save indexes\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'base_U_adaptation'"
     ]
    }
   ],
   "source": [
    "# quick settings\n",
    "n_splits = 5  #6\n",
    "convolved = True\n",
    "\n",
    "# get vtc filenames and settings\n",
    "runz = [1,2,3,4,5,6,7,8,9,10]\n",
    "save_predict = False\n",
    "\n",
    "# set modeltype\n",
    "modeltype = LinearRegression() #can be LinearRegression (ols), Ridge(alpha=..), Lasso(alpha=..)  etc.\n",
    "key_ai = ['raw_scores', 'coefs', 'intercepts', 'correlation'] # what keys to median and mean across folds\n",
    "\n",
    "\n",
    "## --- DEFINING TEST TRAIN SPLIT ---\n",
    "\n",
    "# get test train splits per run\n",
    "train_matrix, test_matrix = train_test_splits(stim_df, n_splits)\n",
    "\n",
    "\n",
    "## --- BASED ON TUNING PREF AND TW LOAD DESIRED COLUMNS OUT OF DF ---\n",
    "\n",
    "# load tonotopy vmp\n",
    "vmp_df = pd.DataFrame(vmp_img[msk])\n",
    "\n",
    "# load voxeltimecourse filenames\n",
    "vtc_fns = [join(vtc_dir, fn(pp,ses,run)) for run in runz]\n",
    "\n",
    "# predefine dictionaries for saving regression results\n",
    "scores = {}\n",
    "\n",
    "# predifine indexes arrays for reconstruction\n",
    "idx1 = np.array([], dtype=int)\n",
    "idx2 = np.array([], dtype=int)\n",
    "idx3 = np.array([], dtype=int)\n",
    "\n",
    "## --- LOOP OVER FULL GRID OF PREFS * TWS ---\n",
    "\n",
    "# create grid and do full loop\n",
    "for tpref, tw in itertools.product(pref_range, sharp_range):\n",
    "    # TEMP FOR TIMING\n",
    "    st_temp = time.time() #start timing\n",
    "\n",
    "    # get grid position indexes for tuning pref and tw\n",
    "    grid_idx = vmp_df.loc[np.isclose(vmp_df[0], tpref, rtol=1e-3) & \n",
    "                          np.isclose(vmp_df[1], tw, rtol=1e-3)].index\n",
    "    \n",
    "    # check if any boxels in gridposition\n",
    "    if grid_idx.empty == False:\n",
    "        \n",
    "        # use these grid positions to get a chuck of the mask\n",
    "        msk_chunk = [i[grid_idx] for i in msk]\n",
    "\n",
    "        # load vtc for chunk\n",
    "        y, run_nr = stim_io.load_vtc_chunk_runs(vtc_fns, msk_chunk)\n",
    "        y = y.transpose() # transpose to make k-fold splits simpler\n",
    "\n",
    "        # zscore y\n",
    "        y = zs_per_run(y, run_nr)\n",
    "        \n",
    "        # load xnames for this columns\n",
    "        col_names = stim_io.get_tw_collumns(tr_df, tpref, tw, convolved=convolved)\n",
    "        \n",
    "        # translate grid positions to mask indexes and save full list\n",
    "        idx1 = np.concatenate((idx1, msk[0][grid_idx]))\n",
    "        idx2 = np.concatenate((idx2, msk[1][grid_idx]))\n",
    "        idx3 = np.concatenate((idx3, msk[2][grid_idx]))\n",
    "\n",
    "# --- LOOP OVER ALL MODELS FOR DOING SET THEORY --- \n",
    "        for model in models:\n",
    "\n",
    "            # get X for this model \n",
    "            col_regressors = extract_sublist(col_names, model_regressors[model])\n",
    "            X = tr_df[col_regressors].to_numpy()\n",
    "            #print(f'{model}:\\n\\t\\t{extract_sublist(col_names, model_regressors[model])}\\n')\n",
    "\n",
    "            # zscore y\n",
    "            X = zs_per_run(X, run_nr)\n",
    "            \n",
    "            # (re)predefine dictionary for storing this models all folds\n",
    "            nscore = {}\n",
    "        \n",
    "        \n",
    "### --- RUN SCRIPT TO DO KFOLDED REGRESSION, AND PARSE OUTPUT IN MEANINGFULL WAY\n",
    "            # get cross validated scores based on previously defined test/train splits\n",
    "            for fold in range(len(train_matrix)):\n",
    "                # save indexes for text number in array\n",
    "                train_idx = np.argwhere(np.in1d(run_nr, train_matrix[fold])).flatten()\n",
    "                test_idx = np.argwhere(np.in1d(run_nr, test_matrix[fold])).flatten()\n",
    "\n",
    "                # select train and test sets for fold\n",
    "                X_train, X_test = X[train_idx], X[test_idx]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "                # do the regression\n",
    "                nscore[fold+1] = model_fit(modeltype, \n",
    "                                           X_train,\n",
    "                                           X_test,\n",
    "                                           y_train,\n",
    "                                           y_test,\n",
    "                                           save_predict=save_predict)\n",
    "\n",
    "            # check if we update previous chunk or initate dict using this one\n",
    "            if model not in scores:\n",
    "                scores[model] = nscore\n",
    "            else:\n",
    "                # combine all the folds into one dictionary - aditionally append chunks\n",
    "                for fold in range(len(train_matrix)):\n",
    "                    scores[model][fold+1] = {key : np.concatenate((scores[model][fold+1][key], \n",
    "                                                                   nscore[fold+1][key])) for key in nscore[fold+1]}\n",
    "\n",
    "\n",
    "### --- DO ANOTHER REGRESSION WITHOUT CROSS VALIDATION, TO VALIDATE RESULTS ---\n",
    "            # get non-crossvalidated scores\n",
    "            nscore_noncv = non_cv_fit(modeltype, \n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        save_predict=save_predict)\n",
    "            # nest 'score' inside an array to allow for concatenation\n",
    "            nscore_noncv['score'] = np.array([nscore_noncv['score']]) \n",
    "            # check if exist otherwise add to existing\n",
    "            if 'non-cv' not in scores[model]:\n",
    "                scores[model]['non-cv'] = nscore_noncv\n",
    "            else:\n",
    "                scores[model]['non-cv'] = {key : np.concatenate((scores[model]['non-cv'][key], \n",
    "                                                                 nscore_noncv[key])) for key in nscore_noncv}\n",
    "\n",
    "\n",
    "### --- STORE MEDIAN AND MEAN ACROSS FOLDS ---\n",
    "for model in models:\n",
    "    for k in key_ai:\n",
    "        cv_scores = {'median':  np.median(np.array([scores[model][fold+1][k] for \n",
    "                                                    fold in range(len(train_matrix))]), axis=0),\n",
    "                     'mean':   np.nanmean(np.array([scores[model][fold+1][k] for \n",
    "                                                    fold in range(len(train_matrix))]), axis=0)}\n",
    "        scores[model][k] = cv_scores\n",
    "    \n",
    "# save indexes\n",
    "scores['indexes'] = (idx1, idx2, idx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bd2c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove files\n",
    "for fp in vtc_fns:\n",
    "    os.remove(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b823a1",
   "metadata": {},
   "source": [
    "cleanup and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08b59935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# make dir if doesnt esist\n",
    "if not os.path.exists(join(mridat_dir, pp_dir(pp, ses), 'Betas')):\n",
    "    os.mkdir(join(mridat_dir, pp_dir(pp, ses), 'Betas'))\n",
    "\n",
    "# pickle the results\n",
    "with open(join(mridat_dir, pp_dir(pp, ses), 'Betas/scores.pickle'), 'wb') as handle:\n",
    "    pickle.dump(scores, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63667a9e",
   "metadata": {},
   "source": [
    "loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c3a4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(mridat_dir, pp_dir(pp, ses), 'Betas/scores.pickle'), 'rb') as handle:\n",
    "    scores = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b9f04cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc753bbc400>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.hist(scores['base_U_adaptation_U_prediction']['non-cv']['correlation'], 20, alpha=0.7, label='full')\n",
    "plt.hist(scores['prediction']['non-cv']['correlation'], 20, alpha=.7, label='pred')\n",
    "plt.hist(scores['base_U_adaptation']['non-cv']['correlation'], 20, alpha=.7, label='base')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa8708d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_map(mapname, mapthreshold=1.65, mapupperthreshold=8.0):\n",
    "    FDRTableInfo = np.array([], dtype=np.float64)\n",
    "    FDRTableInfo.shape = (0,3)\n",
    "    returnmap = {'TypeOfMap': 1,\n",
    "     'MapThreshold': mapthreshold,\n",
    "     'UpperThreshold': mapupperthreshold,\n",
    "     'MapName': mapname,\n",
    "     'RGB positive min': np.array([255,   0,   0], dtype=np.uint8),\n",
    "     'RGB positive max': np.array([255, 255,   0], dtype=np.uint8),\n",
    "     'RGB negative min': np.array([255,   0, 255], dtype=np.uint8),\n",
    "     'RGB negative max': np.array([  0,   0, 255], dtype=np.uint8),\n",
    "     'UseVMPColor': 0,\n",
    "     'LUTFileName': '<default>',\n",
    "     'TransparentColorFactor': 1.0,\n",
    "     'ClusterSizeThreshold': 50,\n",
    "     'EnableClusterSizeThreshold': 0,\n",
    "     'ShowValuesAboveUpperThreshold': 1,\n",
    "     'DF1': 249,\n",
    "     'DF2': 1,\n",
    "     'ShowPosNegValues': 3,\n",
    "     'NrOfUsedVoxels': 45555,\n",
    "     'SizeOfFDRTable': 0,\n",
    "     'FDRTableInfo': FDRTableInfo,\n",
    "     'UseFDRTableIndex': 0}\n",
    "    return(returnmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca5859ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = np.array([[0.33, 0.33,0.34],\n",
    "                [0.264, 0.264,0.472],\n",
    "                [0.198, 0.198,0.604],\n",
    "                [0.132, 0.132,0.736],\n",
    "                [0.066, 0.066,0.868],\n",
    "                [0, 0,1],\n",
    "                [0.1225, 0,0.8775],\n",
    "                [0.245,0,0.755],\n",
    "                [0.3675,0,0.6325],\n",
    "                [0.49,0,0.51],\n",
    "                [0.34,0.33,0.33],\n",
    "                [0.472,0.264,0.264],\n",
    "                [0.604,0.198,0.198],\n",
    "                [0.736,0.132,0.132],\n",
    "                [0.868,0.066,0.066],\n",
    "                [1,0,0],\n",
    "                [0.8775,0,0.1225],\n",
    "                [0.755,0,0.245],\n",
    "                [0.6325,0,0.3675],\n",
    "                [0.51,0,0.49]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a91edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = np.array([[1,0,0],\n",
    "              [0.833333333333333,0.166666666666667,0],\n",
    "              [0.666666666666667,0.333333333333333,0],\n",
    "              [0.5,0.5,0],\n",
    "              [0.25,0.75,0],\n",
    "              [0,1,0],\n",
    "              [0,0.75,0.25],\n",
    "              [0,0.5,0.5],\n",
    "              [0,0.333333333333333,0.666666666666667],\n",
    "              [0,0.166666666666667,0.833333333333333],\n",
    "              [0,0,1],\n",
    "              [0.166666666666667,0,0.833333333333333],\n",
    "              [0.333333333333333,0,0.666666666666667],\n",
    "              [0.5,0,0.5],\n",
    "              [0.833333333333333,0,0.166666666666667],\n",
    "              [0.666666666666667,0,0.333333333333333],\n",
    "              [0.333,0.333,0.333],\n",
    "              [0.1665,0.1665,0.6665],\n",
    "              [0.6665,0.1665,0.1665],\n",
    "              [0.1665,0.6665,0.1665]])\n",
    "    \n",
    "def closest_row(lookup, coord):\n",
    "    \"\"\"quick function so search for the closest coordinate in the lookup table\n",
    "    then convert this to the -10 +10 range of brainvoyager\"\"\"\n",
    "    lookup = np.array(lookup)\n",
    "    coords = np.array(coord)\n",
    "    bv_value = np.concatenate((np.arange(1,11,1), np.arange(-1,-11,-1)))\n",
    "    distances = np.linalg.norm(lookup[np.newaxis, :, :] - coords[:, np.newaxis, :], axis=2)\n",
    "    return bv_value[np.argmin(distances, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "921df8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set theory calculations\n",
    "pred_unique = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores'] - scores['base_U_adaptation']['non-cv']['raw_scores']\n",
    "base_unique = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores'] - scores['prediction']['non-cv']['raw_scores']\n",
    "common_part = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores'] - pred_unique - base_unique\n",
    "\n",
    "# take full matrix and stack/normalize\n",
    "full_mat = np.stack((pred_unique, common_part, base_unique)) # stack 3 parts of sets\n",
    "full_mat = full_mat.clip(min=0) / full_mat.clip(min=0).sum(axis=0)  # normalize matrix\n",
    "\n",
    "# get -10 10 range\n",
    "map_val = closest_row(lookup, full_mat.transpose())\n",
    "\n",
    "# so some sellection\n",
    "sellection = scores['base_U_adaptation_U_prediction']['non-cv']['correlation'] < 0.05\n",
    "map_val[sellection] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff23d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stranslate data to vmp\n",
    "\n",
    "# pp = 2\n",
    "nr_models = 1\n",
    "\n",
    "# filenames\n",
    "mridat_dir = '/media/jorvhar/Data1/MRIData/PreProc'\n",
    "pp_dir = lambda pp, ses : f'S{pp:02d}_SES{ses}'\n",
    "betas_dir = 'Betas'\n",
    "\n",
    "# tonotopy and mask filenames\n",
    "tonotopy_vmp = 'prf_permutations_for_S2.vmp'\n",
    "\n",
    "# load vmp image\n",
    "score_vmp_head, vmp_img = bvbabel.vmp.read_vmp(join(mridat_dir, pp_dir(pp,1), betas_dir, tonotopy_vmp))\n",
    "score_vmp_full = np.zeros((list(vmp_img.shape[:-1]) + [nr_models * 2]))\n",
    "score_vmp_head['NrOfSubMaps'] = nr_models\n",
    "score_vmp_head['Map'] = []\n",
    "\n",
    "# full map\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = map_val\n",
    "score_vmp_full[:,:,:,0] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('pred', mapthreshold=0, mapupperthreshold=10))\n",
    "\n",
    "bvbabel.vmp.write_vmp('/media/jorvhar/Data1/MRIData/PreProc/S0{}_SES1/Betas/map2023-1.vmp'.format(pp),score_vmp_head, score_vmp_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ce28ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8., 8., 5., ..., 0., 0., 7.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sellection = scores['base_U_adaptation_U_prediction']['non-cv']['correlation'] < 0.035\n",
    "full_mat[:,sellection] = 0\n",
    "\n",
    "np.round(full_mat[0,:] * 10)  # prediction map\n",
    "np.round(full_mat[1,:] * 10)  # common map\n",
    "np.round(full_mat[2,:] * 10)  # baseline map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5efb4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stranslate data to vmp\n",
    "\n",
    "# pp = 1\n",
    "nr_models = 3\n",
    "\n",
    "# filenames\n",
    "mridat_dir = '/media/jorvhar/Data1/MRIData/PreProc'\n",
    "pp_dir = lambda pp, ses : f'S{pp:02d}_SES{ses}'\n",
    "betas_dir = 'Betas'\n",
    "\n",
    "# tonotopy and mask filenames\n",
    "tonotopy_vmp = 'prf_permutations_for_S2.vmp'\n",
    "\n",
    "# load vmp image\n",
    "score_vmp_head, vmp_img = bvbabel.vmp.read_vmp(join(mridat_dir, pp_dir(pp,1), betas_dir, tonotopy_vmp))\n",
    "score_vmp_full = np.zeros((list(vmp_img.shape[:-1]) + [nr_models * 2]))\n",
    "score_vmp_head['NrOfSubMaps'] = nr_models\n",
    "score_vmp_head['Map'] = []\n",
    "\n",
    "# full map\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = np.round(full_mat[0,:] * 10)\n",
    "score_vmp_full[:,:,:,0] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('pred', mapthreshold=0, mapupperthreshold=10))\n",
    "\n",
    "# full map\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = np.round(full_mat[1,:] * 10)\n",
    "score_vmp_full[:,:,:,1] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('common', mapthreshold=0, mapupperthreshold=10))\n",
    "\n",
    "# full map\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = np.round(full_mat[2,:] * 10)\n",
    "score_vmp_full[:,:,:,2] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('baseline', mapthreshold=0, mapupperthreshold=10))\n",
    "\n",
    "bvbabel.vmp.write_vmp('/media/jorvhar/Data1/MRIData/PreProc/S0{}_SES1/Betas/map1234.vmp'.format(pp),score_vmp_head, score_vmp_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f338a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stranslate data to vmp\n",
    "\n",
    "# pp = 1\n",
    "nr_models = 6\n",
    "multiplyer = 50 # for floating point errros, use multiplyer\n",
    "\n",
    "# filenames\n",
    "mridat_dir = '/media/jorvhar/Data1/MRIData/PreProc'\n",
    "pp_dir = lambda pp, ses : f'S{pp:02d}_SES{ses}'\n",
    "betas_dir = 'Betas'\n",
    "\n",
    "# tonotopy and mask filenames\n",
    "tonotopy_vmp = 'prf_permutations_for_S2.vmp'\n",
    "\n",
    "# load vmp image\n",
    "score_vmp_head, vmp_img = bvbabel.vmp.read_vmp(join(mridat_dir, pp_dir(pp,1), betas_dir, tonotopy_vmp))\n",
    "score_vmp_full = np.zeros((list(vmp_img.shape[:-1]) + [nr_models * 2]))\n",
    "score_vmp_head['NrOfSubMaps'] = nr_models * 2\n",
    "score_vmp_head['Map'] = []\n",
    "\n",
    "#############################\n",
    "# FIRST DO EVERYTHING NON-CV\n",
    "#############################\n",
    "\n",
    "# set theory calculations\n",
    "pred_unique = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores'] - scores['base_U_adaptation']['non-cv']['raw_scores']\n",
    "base_unique = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores'] - scores['prediction']['non-cv']['raw_scores']\n",
    "common_part = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores'] - pred_unique - base_unique\n",
    "\n",
    "# base model\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = scores['base_U_adaptation']['non-cv']['raw_scores'] * multiplyer\n",
    "score_vmp_full[:,:,:,0] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('base_U_adaptation (non-cv)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# pred model\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = scores['prediction']['non-cv']['raw_scores'] * multiplyer\n",
    "score_vmp_full[:,:,:,1] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('prediction (non-cv)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# full model\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores'] * multiplyer\n",
    "score_vmp_full[:,:,:,2] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('base_U_adaptation_U_prediction (non-cv)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# base unique\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = base_unique * multiplyer\n",
    "score_vmp_full[:,:,:,3] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('base_unique (non-cv)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# pred unique\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = pred_unique * multiplyer\n",
    "score_vmp_full[:,:,:,4] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('pred_unique (non-cv)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# shared\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = common_part * multiplyer\n",
    "score_vmp_full[:,:,:,5] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('base_N_adaptation_N_prediction (non-cv)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "\n",
    "#####################################\n",
    "# do same on cross validated results\n",
    "#####################################\n",
    "\n",
    "# set theory calculations\n",
    "pred_unique = scores['base_U_adaptation_U_prediction']['raw_scores']['mean'] - scores['base_U_adaptation']['raw_scores']['mean']\n",
    "base_unique = scores['base_U_adaptation_U_prediction']['raw_scores']['mean'] - scores['prediction']['raw_scores']['mean']\n",
    "common_part = scores['base_U_adaptation_U_prediction']['raw_scores']['mean'] - pred_unique - base_unique\n",
    "\n",
    "# base model\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = scores['base_U_adaptation']['raw_scores']['mean'] * multiplyer\n",
    "score_vmp_full[:,:,:,6] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('base_U_adaptation (cv mean)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# pred model\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = scores['prediction']['raw_scores']['mean'] * multiplyer\n",
    "score_vmp_full[:,:,:,7] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('prediction (cv mean)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# full model\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = scores['base_U_adaptation_U_prediction']['raw_scores']['mean'] * multiplyer\n",
    "score_vmp_full[:,:,:,8] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('base_U_adaptation_U_prediction (cv mean)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# base unique\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = base_unique * multiplyer\n",
    "score_vmp_full[:,:,:,9] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('base_unique (cv mean)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# pred unique\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = pred_unique * multiplyer\n",
    "score_vmp_full[:,:,:,10] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('pred_unique (cv mean)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "# shared\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = common_part * multiplyer\n",
    "score_vmp_full[:,:,:,11] = score_vmp\n",
    "score_vmp_head['Map'].append(set_map('base_N_adaptation_N_prediction (cv mean)', mapthreshold=0.0001, mapupperthreshold=0.25))\n",
    "\n",
    "bvbabel.vmp.write_vmp('/media/jorvhar/Data1/MRIData/PreProc/S0{}_SES2/Betas/session2.vmp'.format(pp),score_vmp_head, score_vmp_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b654030",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseidx = np.where(map_val == 7)[0][100] # index pure baseline\n",
    "mixidx = np.where(map_val == -1)[0][100] # fully mixed\n",
    "predidx = np.where(map_val == -6)[0][0] # pure prediction\n",
    "predbaseidx = np.where(map_val == 10)[0][100] # pred + adapt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd289304",
   "metadata": {},
   "source": [
    "### variance partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61bae64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2,venn3\n",
    "import numpy as np \n",
    "\n",
    "def two_way_varpart(A,B,AuB,correct_R2s=True,return_sep=True):\n",
    "    \"\"\"2-way variance partitioning. Handles scalars (single R2s) and vectors (multiple R2s).\n",
    "    \n",
    "    By default, this function implements a correction to handle cross-validated R2s. \n",
    "    That is, estimates and adds the smallest bias vector (in an L2-sense) such that the \n",
    "    set theoretic equations yield no inconsistent results. See De Heer, Huth, et al. \n",
    "    \n",
    "    For info, see:\n",
    "    - de Heer, Huth, et al. (2017) Journal of Neuroscience, 37(27), 6539-6557.\n",
    "\n",
    "    In:\n",
    "    positional args: \n",
    "    - (A,B,AuB): floats or np.array, shape(n_resp)\n",
    "        R2 values for GLMs with each feature space, and the union of them. \n",
    "    - return_sep: bool (Default: True)\n",
    "        if True, returns separate variable for each partition (i.e. as tuple of scalars/vectors)  \n",
    "        If False, returns values in vectorised form (i.e. vector of scalars / matrix of row-vectors)\n",
    "    -correct_R2s: Bool (Default: True)\n",
    "        Implement correction to avoid impossible values.\n",
    "    \n",
    "    Out:\n",
    "    - 6 separate variables for each (adjusted) input R2 and each partition \n",
    "        if return_sep=True\n",
    "    OR\n",
    "    - 1 variable for all (adjusted) input R2s and partitions \n",
    "        (6-dimensional vector if input is scalar; (6 x n_resp) dim matrix if input is vector)\n",
    "    order of output:\n",
    "    (A,B,C, AuB, # input R2s (adjusted values if needed)\n",
    "     A*,B*, AnB) # output partitions\n",
    "    \n",
    "    -------\n",
    "    MH 2020\n",
    "    -------\n",
    "    \"\"\"\n",
    "    eqs=np.array([[0,-1,1],  # A_ =  AuB - B \n",
    "                  [-1,0,1],  # B_ =  AuB - A \n",
    "                  [1,1,-1]]) # AnB=  A+B -AuB \n",
    "    all_ABAuB=np.vstack((A,B,AuB))\n",
    "    all_ABAuB[all_ABAuB<0]=0 # ignore negative values \n",
    "    \n",
    "    # estimate biases (still iterative over responses...)\n",
    "    all_biases=np.zeros_like(all_ABAuB)\n",
    "    if correct_R2s:\n",
    "        for vox_i, ABAuB in enumerate(all_ABAuB.T):\n",
    "            all_biases[:,vox_i]=_est_bias_2wayVP(ABAuB[0],ABAuB[1],ABAuB[2])\n",
    "        \n",
    "    all_ABAuB_adjusted=all_ABAuB+all_biases\n",
    "    all_A_B_AnB=eqs.dot(all_ABAuB_adjusted)\n",
    "\n",
    "    if return_sep: # if return values as separate variables (i.e. as tuple of scalars/vectors)\n",
    "        return(all_ABAuB_adjusted[0],all_ABAuB_adjusted[1],all_ABAuB_adjusted[2],\n",
    "           all_A_B_AnB[0],all_A_B_AnB[1],all_A_B_AnB[2])\n",
    "    else: # if return vectorised form \n",
    "        return(np.vstack((all_ABAuB_adjusted,all_A_B_AnB)))\n",
    "\n",
    "def _est_bias_2wayVP(A,B,AuB):\n",
    "    \"\"\"estimate bias vector for A*,B* and AnB in 2 way variance partitioning.\n",
    "    in:\n",
    "    - A,B,AuB: floats\n",
    "        R2 for A B and AuB feauterespaces\n",
    "    returns:\n",
    "    -b123: bias vector for A,B,AnB\n",
    "    \"\"\"\n",
    "    def obj(x):\n",
    "        return(np.linalg.norm(x)) #  l2 norm \n",
    "\n",
    "    def c1(x): # A_ >=0; in other words, AuB+x[2] - B+x[1] >=0\n",
    "        return((AuB+x[2]) - (B+x[1]))\n",
    "\n",
    "    def c2(x): # B_ >=0; in other words, AuB+x[2] - A+x[0] >=0\n",
    "        return((AuB+x[2]) - (A+x[0]))\n",
    "\n",
    "    def c3(x): # AnB >=0; in other words, (A+x[0]) + (B+x[1]) - (AuB+x[2])] >=0\n",
    "        return((A+x[0]) + (B+x[1]) - (AuB+x[2]))\n",
    "    cons=(\n",
    "        {'type':'ineq','fun':c1},\n",
    "        {'type':'ineq','fun':c2},\n",
    "        {'type':'ineq','fun':c3},\n",
    "    )\n",
    "    res=minimize(obj,np.random.rand(3)*.001,constraints=cons,bounds=((None,0),)*3,)\n",
    "    if not res.success: \n",
    "        print('initial faillure... trying harder......')\n",
    "        res = minimize(obj,np.random.rand(3)*.001,constraints=cons,bounds=((None,0),)*3,\n",
    "                      method='SLSQP',options={'maxiter':999})\n",
    "        if res.success: return(res.x)\n",
    "        else: # if still not, check what's happening \n",
    "            print('A',A);print('B:',B);print('AuB',AuB)\n",
    "            set_trace() # to be commented later on\n",
    "            return(np.nan(3))\n",
    "    else: \n",
    "        return(res.x)\n",
    "def _est_bias_3wayVP(A,B,C,AuB,AuC,BuC,AuBuC, only_overlap=True):\n",
    "    \"\"\"estimate bias vector for A*,B*,C* and AnB,AnC,BnC,AnBnC in 3 way variance partitioning.\n",
    "    in:\n",
    "    - A,B,C,AuB,AuC,BuC,AuBuC: floats\n",
    "        R2 for A B and AuB feauterespaces\n",
    "    returns:\n",
    "    -b123: bias vector for A,B,C,AuB,AuC,BuC,AuBuC\n",
    "    \"\"\"\n",
    "    def obj(x):\n",
    "        return(np.linalg.norm(x)) #  l2 norm \n",
    "    \n",
    "    def c1(x): # A*  = AuBuC - BuC  \n",
    "        return((AuBuC+x[6]) - (BuC+x[5]))\n",
    "    def c2(x): # B* >=0; in other words:  (AuBuC+x[6]) - (AuC+x[4]) >=0\n",
    "        return((AuBuC+x[6]) - (AuC+x[4]))\n",
    "    def c3(x): # C*  >=0; in other words AuBuC - AuB\n",
    "        return((AuBuC+x[6]) - (AuB+x[3]))\n",
    "    def c4(x):# AnB*= AuC + BuC - C - AuBuC\n",
    "        return((AuC+x[4]) + (BuC+x[5]) - (C+x[2])- (AuBuC+x[6]))\n",
    "    def c5(x):# AnC* = AuB + BuC - B - AuBuC\n",
    "        return((AuB+x[3]) + (BuC+x[5]) - (B+x[1])- (AuBuC+x[6]))\n",
    "    def c6(x):# BnC*= AuB + AuC - A - AuBuC\n",
    "        return((AuB+x[3]) + (AuC+x[4]) - (A+x[0])- (AuBuC+x[6]))\n",
    "    def c7(x):# AnBnC =  AuBuC + A+B+C - AuB - AuC -BuC\n",
    "        return((AuBuC+x[6]) + (A+x[0]) + (B+x[1]) + (C+x[2]) -\n",
    "               (AuB+x[3]) - (AuC+x[4]) - (BuC+x[5]))\n",
    "    \n",
    "    # define constraintes: all funcs >=0\n",
    "    np.random.seed(123)\n",
    "    if only_overlap == True: \n",
    "        cons=tuple({'type':'ineq','fun':c} for c in [c4,c5,c6,c7])\n",
    "        res=minimize(obj,np.random.rand(7)*-.0001,constraints=cons,bounds=((None,0),)*7,)\n",
    "    else: \n",
    "        cons=tuple({'type':'ineq','fun':c} for c in [c1,c2,c3,c4,c5,c6,c7])   \n",
    "        res=minimize(obj,np.random.rand(7)*-.0001,constraints=cons,bounds=((None,0),)*7,)\n",
    "    \n",
    "    if not res.success: \n",
    "        print('initial faillure... trying harder......')\n",
    "        res = minimize(obj,np.random.rand(7)*-.0001,constraints=cons,bounds=((0,None),)*7,\n",
    "                      method='SLSQP',options={'maxiter':999})\n",
    "        if res.success: return(res.x)\n",
    "        else: # if still not, check what's happening \n",
    "            print('A',A);print('B:',B);print('AuB',AuB)\n",
    "            set_trace() # to be commented later on\n",
    "            return(np.nan(3))\n",
    "    else: \n",
    "        return(res.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6ab0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2way_varpartven(varpartres,avgfun=np.mean,mask=None,formatter=None,\n",
    "                        labels=['A \\n features', 'B \\n features'],\n",
    "                         newfig=False,ax=None, alpha=0.5):\n",
    "    \"\"\"wrapper function to plot results coming from `two_way_varpart` function.\n",
    "    \n",
    "    in: \n",
    "    - varpartres (tuple)\n",
    "        tuple of res from `three_way_varpart`:\n",
    "        with order:\n",
    "              (A, B, AuB,,   # input R2s (adjusted values if needed)\n",
    "              A*,B*,C*,AnB*,AnC*,BnC*,AnBnC) # output partitions (index 7 and beyond)    \n",
    "              7, 8, 9, 10,   11,  12, 13\n",
    "    - avgfun: callable (default: np.mean)\n",
    "        if you average over small number of responses, maybe use median?\n",
    "    - get_res: None | int/float | callable \n",
    "        which result to get. can be either a callable (e.g. mean function) or an index (specific voxel)\n",
    "        defaults to mean if None\n",
    "    - labels: Sequenceof 3 strings\n",
    "        labels of the three venns\n",
    "    - formatter: callable | None\n",
    "        function doing the label formatting. defaults to converting to % and rouning\n",
    "    \n",
    "    returns:\n",
    "    -figure: mpl figure \n",
    "    \"\"\"\n",
    "    if not formatter: formatter=lambda x: \"{}\".format(round(x*100,4))\n",
    "    get_rez=avgfun if (mask is None) else lambda x: avgfun(x[mask])            \n",
    "    if newfig: plt.figure()\n",
    "    varpartrez_orderd=tuple(varpartres[vp_i] for vp_i in [3, 4, 5])  # check this\n",
    "    fig= venn2(subsets=tuple(get_rez(vp) for vp in varpartrez_orderd),\n",
    "               set_labels=labels,subset_label_formatter=formatter,ax=ax, alpha=alpha)\n",
    "    return(fig)\n",
    "\n",
    "def organise_3way_varpartres(vpres_in,lbls=['Syn','Sem','Lex'],ignorenegative=True):\n",
    "    \"\"\"From tuple of 3-way varpartres, make a dict with clear labels.\n",
    "    \n",
    "    \n",
    "    In: \n",
    "    - vpres_in: Tuple (np.array,np.array,...)\n",
    "        14 arrays; output from ``three_way_varpart``\n",
    "    - lbls: List / Sequence of strings\n",
    "        3 names for the fundamental feature spaces \n",
    "    -------------------\n",
    "    Out:\n",
    "    - varpart_dict:\n",
    "        dictionary with all 14 arrays (7 sets, 7 subsets) plus the 3 pairwise intersects\n",
    "    \n",
    "     E.g. res['Syn_n_Sem_n_Phon'] for the intersection of syntax, semantics and phonemes\n",
    "\n",
    "    for a tuple of varpartres results and 3 lables, make a dict with transparent names.\n",
    "    also include intersections.\"\"\"\n",
    "    fmt= lambda x_str: x_str.replace('A',lbls[0]).replace('B',lbls[1]).replace('C',lbls[2])\n",
    "    vpres_lbls=('A','B', 'C','A_u_B','A_u_C','B_u_C','A_u_B_u_C',\n",
    "                'A*','B*','C*','A_n_B*','A_n_C*','B_n_C*','A_n_B_n_C')\n",
    "    vp_dict={vp_lbl:vpres for vpres,vp_lbl in zip(vpres_in,vpres_lbls)}\n",
    "    vp_dict['A_n_B']=vp_dict['A']+vp_dict['B'] - vp_dict['A_u_B']\n",
    "    vp_dict['A_n_C']=vp_dict['A']+vp_dict['C'] - vp_dict['A_u_C']\n",
    "    vp_dict['B_n_C']=vp_dict['B']+vp_dict['C'] - vp_dict['B_u_C']\n",
    "    \n",
    "    if ignorenegative == True:\n",
    "        for k,v in vp_dict.items(): vp_dict[k][v<0]=0. # ignore negative vals\n",
    "    # string format and return. \n",
    "    return({fmt(k):v for k,v in vp_dict.items()})\n",
    "\n",
    "\n",
    "def three_way_varpart(A,B,C,AuB,AuC,BuC,AuBuC,correct_R2s=False):\n",
    "    \"\"\"3-way variance partitioning. Handles scalars (single R2s) and vectors (multiple R2s).\n",
    "    \n",
    "    By default, thi function implements a correction to handle cross-validated R2s. \n",
    "    That is, estimates and adds the smallest bias vector (in an L2-sense) such that the \n",
    "    set theoretic equations yield no inconsistent results. See De Heer, Huth, et al. \n",
    "    \n",
    "    In:\n",
    "    positional args: \n",
    "    - (A,B,C,AuB,AuC,BuC,AuBuC): floats or np.array, shape(n_resp)\n",
    "        R2 values for GLMs with each feature space, each pair, and all featurespaces together.\n",
    "    -correct_R2s: Bool (Default: True)\n",
    "        Implement correction to avoid impossible values.\n",
    "    \n",
    "    Out:\n",
    "    - 14 tuple of scalars/vectors for each (adjusted) input R2 and computed each partition \n",
    "         the input R2s that are used in the set-theoretic equations are returned to check correction\n",
    "            order of output:\n",
    "            -(A, B, C,AuB,AuC,BuC,AuBuC,    # input R2s (adjusted values if needed)\n",
    "              A*,B*C*,AnB*,AnC*,BnC*,AnBnC) # output partitions (index 7 and beyond)    \n",
    "    -------\n",
    "    MH 2020\n",
    "    -------\n",
    "    For info, see:\n",
    "    de Heer, Huth, et al. (2017) Journal of Neuroscience, 37(27), 6539-6557.\n",
    "    \"\"\"\n",
    "    # express set theoretic equations in matrix form\n",
    "                 # A   B   C  AuB AuC BuC AuBuC\n",
    "    eqs=np.array([[0 , 0 , 0 , 0 , 0 ,-1 , 1 ],  # A*  = AuBuC - BuC  \n",
    "                  [0 , 0 , 0 , 0 ,-1 , 0 , 1 ],  # B*  = AuBuC - AuC  \n",
    "                  [0 , 0 , 0 ,-1 , 0 , 0 , 1 ],  # C*  = AuBuC - AuB\n",
    "                  [0 , 0 , -1, 0 , 1 , 1 , -1],  # AnB*= AuC + BuC - C - AuBuC\n",
    "                  [0 , -1, 0 , 1 , 0 , 1 , -1],  # AnC*= AuB + BuC - B - AuBuC\n",
    "                  [-1, 0 , 0 , 1 , 1 , 0 , -1],  # BnC*= AuB + AuC - A - AuBuC\n",
    "                  [1 , 1 , 1 ,-1 ,-1 ,-1 , 1 ]]) # AnBnC* =  AuBuC + A+B+C -AuB - AuC -BuC\n",
    "\n",
    "    all_ABC_pluspairs=np.vstack((A,B,C,AuB,AuC,BuC,AuBuC))\n",
    "    all_ABC_pluspairs[all_ABC_pluspairs<0]=0 # ignore negative input values \n",
    "    \n",
    "    # estimate biases (iterative over responses but should be reasonably fast...)\n",
    "    all_biases=np.zeros_like(all_ABC_pluspairs)\n",
    "    if correct_R2s: # loop over responses (voxels, sensors, whatever)\n",
    "        for vox_i, these_ABCpluspairs in enumerate(all_ABC_pluspairs.T):\n",
    "            all_biases[:,vox_i]=_est_bias_3wayVP(*(v for v in these_ABCpluspairs),)\n",
    "        \n",
    "    all_ABC_pluspairs_adjusted=all_ABC_pluspairs+all_biases\n",
    "    all_ABC_derived = np.round(eqs.dot(all_ABC_pluspairs_adjusted),14) # estimate partition sizes \n",
    "\n",
    "    # if return values as separate variables (i.e. as tuple of scalars/vectors)\n",
    "    return(*(v for v in np.vstack((all_ABC_pluspairs_adjusted,all_ABC_derived))),)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d089838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib_venn._common.VennDiagram at 0x7fc745e70b80>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = scores['base_U_adaptation']['non-cv']['raw_scores']\n",
    "B = scores['prediction']['non-cv']['raw_scores']\n",
    "AuB = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores']\n",
    "\n",
    "plot_2way_varpartven(two_way_varpart(A,B,AuB,correct_R2s=False,return_sep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "335a643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseidx = np.where(map_val == 5)[0][100] # index pure baseline\n",
    "mixidx = np.where(map_val == -2)[0][100] # fully mixed\n",
    "predidx = np.where(map_val == -6)[0][0] # pure prediction\n",
    "predbaseidx = np.where(map_val == 10)[0][1] # pred + adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "735b2331",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pimpcollors_venn2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m AuB_sel \u001b[38;5;241m=\u001b[39m AuB[idxtouse]\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m fg\u001b[38;5;241m=\u001b[39m plot_2way_varpartven(two_way_varpart(A_sel,B_sel,AuB_sel,correct_R2s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,return_sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     21\u001b[0m                      labels\u001b[38;5;241m=\u001b[39mlbls,avgfun\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m fg \u001b[38;5;241m=\u001b[39m \u001b[43mpimpcollors_venn2\u001b[49m(fg)\n\u001b[1;32m     26\u001b[0m idrange \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m11\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idrange:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pimpcollors_venn2' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fontsize=20\n",
    "fontsize_pct=fontsize-1\n",
    "title_size=24\n",
    "figsize=(12,12)\n",
    "n_decim=3\n",
    "\n",
    "idxtouse= predbaseidx\n",
    "\n",
    "lbls=['Baseline \\n (low-level + adaptation)','Expectations \\n (D-Rex)']\n",
    "correct_noise=False\n",
    "save_fig=False\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.title('Model Fit\\nPrediction dominated', fontsize=title_size)\n",
    "\n",
    "A_sel   = A[idxtouse].clip(min=0)\n",
    "B_sel   = B[idxtouse].clip(min=0)\n",
    "AuB_sel = AuB[idxtouse].clip(min=0)\n",
    "\n",
    "fg= plot_2way_varpartven(two_way_varpart(A_sel,B_sel,AuB_sel,correct_R2s=False,return_sep=True),\n",
    "                     labels=lbls,avgfun=np.mean, alpha=1)\n",
    "\n",
    "fg = pimpcollors_venn2(fg)\n",
    "\n",
    "\n",
    "idrange = ['10', '01', '11']\n",
    "for idx in idrange:\n",
    "    try:\n",
    "        label = fg.get_label_by_id(idx)\n",
    "        label.set_fontsize(fontsize_pct) \n",
    "        label.set_text(str(np.round(float(label.get_text()), n_decim)))\n",
    "        #label.set_text('') # easy way for empty ones\n",
    "    except AttributeError: print(idx + 'not present')   \n",
    "    \n",
    "for labels in ['A', 'B']:\n",
    "    label = fg.get_label_by_id(labels)\n",
    "    label.set_fontsize(fontsize)\n",
    "    if labels == 'C': label.set_x(label.get_position()[0] + 0.1)\n",
    "\n",
    "if save_fig==True:\n",
    "    fig_name=str(PROJ_ROOT / 'figures' / 'varpart' / 'readingtimes_average')\n",
    "    for fmt in ['png','pdf']:\n",
    "        plt.savefig(f'{fig_name}.{fmt}',facecolor='white',format=fmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pimpcollors_venn3(fig, \n",
    "                idrange=['100', '010', '001', '110', '101', '011', '111'], \n",
    "                colrange=['#b3b4b5', '#f68e65', '#8ca0ca', '#d5a18d', '#a0abc1', '#c39798', '#bca7a7']):\n",
    "    \"\"\"change collors of all elements of a venn diagram\n",
    "    input: fig: figure\n",
    "           idrange: range of all ellements of 3venn diagram\n",
    "           colrange: matching to idrange, set collors for all ellements\n",
    "    output: adjusted figure\"\"\"\n",
    "    \n",
    "    for i in range(len(idrange)):\n",
    "        try: fig.get_patch_by_id(idrange[i]).set_color(colrange[i])\n",
    "        except AttributeError: print(idrange[i] + 'not present')\n",
    "    \n",
    "    return(fig)\n",
    "\n",
    "def pimpcollors_venn2(fig, \n",
    "                idrange=['10', '01', '11'], \n",
    "                colrange=['#EE6D4A', '#475DEC', '#9B659B']):\n",
    "    \"\"\"change collors of all elements of a venn diagram\n",
    "    input: fig: figure\n",
    "           idrange: range of all ellements of 3venn diagram\n",
    "           colrange: matching to idrange, set collors for all ellements\n",
    "    output: adjusted figure\"\"\"\n",
    "    \n",
    "    for i in range(len(idrange)):\n",
    "        try: fig.get_patch_by_id(idrange[i]).set_color(colrange[i])\n",
    "        except AttributeError: print(idrange[i] + 'not present')\n",
    "    \n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47f1fb",
   "metadata": {},
   "source": [
    "## Translate data to `vmp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63316aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stranslate data to vmp\n",
    "\n",
    "score_vmp_full = np.zeros((vmp_img.shape))\n",
    "\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores'] * 100\n",
    "score_vmp_full[:,:,:,0] = score_vmp\n",
    "\n",
    "score_vmp = np.zeros(vmp_img.shape[:3])\n",
    "score_vmp[scores['indexes']] = scores['base_U_adaptation_U_prediction']['non-cv']['raw_scores'] * 100\n",
    "score_vmp_full[:,:,:,1] = score_vmp\n",
    "\n",
    "score_vmp_head = vmp_head.copy()\n",
    "\n",
    "score_vmp_head['Map'][0]['MapName'] = 'medianscores'\n",
    "score_vmp_head['Map'][1]['MapName'] = 'meanscores'\n",
    "\n",
    "bvbabel.vmp.write_vmp('/media/jorvhar/Data1/MRIData/PreProc/S01_SES1/Betas/newdata5.vmp',score_vmp_head, score_vmp_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c758ab",
   "metadata": {},
   "source": [
    "### simulate voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f444359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# settings\n",
    "bias_labels = ['adapthigh', 'expecthigh', 'equal', 'low-level']\n",
    "bias = np.array([[0, 0, 1, 0, 0],   # adapthigh\n",
    "                 [1, 0, 0, 0, 1],   # expecthigh\n",
    "                 [1, 1, 1, 1, 1],   # equal\n",
    "                 [0, 1, 0, 0, 0]])  # low level\n",
    "\n",
    "# grid\n",
    "sim_prefs = np.round(pref_range,4)[::40] # take few prefs\n",
    "sim_sharps = np.round(sharp_range,4)[::4] # take few sharps\n",
    "\n",
    "# predefine simulated voxels\n",
    "simvoxels = np.zeros((len(bias), len(sim_prefs) * len(sim_sharps), len(tr_df)))\n",
    "\n",
    "# go through the full grid\n",
    "for b in range(len(bias)):\n",
    "    \n",
    "    # set linear indexing\n",
    "    linidx = 0\n",
    "    \n",
    "    for prf, shr in itertools.product(sim_prefs, sim_sharps):\n",
    "#         print(bias, prf, shr)\n",
    "        \n",
    "        # calculate the \n",
    "        sim_vtc = scipy.stats.zscore(tr_df[stim_io.get_tw_collumns(tr_df, prf, shr, convolved=convolved)].to_numpy())\n",
    "        sim_vtc = (sim_vtc * bias[b]).sum(axis=1)\n",
    "        \n",
    "        # z-score + noise\n",
    "        sim_vtc = zs(sim_vtc) + np.random.normal(0,0.4,len(sim_vtc))\n",
    "        \n",
    "        # place in array, adjust linidx\n",
    "        simvoxels[b, linidx] = sim_vtc\n",
    "        linidx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961fed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_vtc = scipy.stats.zscore(tr_df[stim_io.get_tw_collumns(tr_df, prf, shr, convolved=convolved)].to_numpy())\n",
    "sim_vtc = (sim_vtc * bias[b]).sum(axis=1)\n",
    "\n",
    "plt.plot(sim_vtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e14ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NEW METHOD - load all runs of chuck\n",
    "\n",
    "# set chucking size\n",
    "chucksize = 50000 #msk[0].shape[0]\n",
    "chucktoanalyse = 0\n",
    "\n",
    "# pp settings\n",
    "nr_runs = 12\n",
    "# pp = 2\n",
    "ses = 2\n",
    "\n",
    "# load only header information\n",
    "head, _ = vtc.read_vtc_msk(fullpath, tuple((np.array([0]),\n",
    "                                            np.array([0]),\n",
    "                                            np.array([0]))))\n",
    "\n",
    "# get expected vtc dim\n",
    "vtcdim = vtc.get_vtc_dims(head)\n",
    "\n",
    "# load full mask and convert to indeces\n",
    "_, msk = bvbabel.msk.read_msk(mskpath)\n",
    "msk = np.where(msk)\n",
    "\n",
    "# devide the mask in chucks based on our chucksize\n",
    "chucked_msk = vtc.chuck_msk(msk, chucksize)\n",
    "\n",
    "# to loop over all chucks we can do\n",
    "#for chuck in chucked_msk: # remove this - just for testing speed\n",
    "chuck = chucked_msk[chucktoanalyse]\n",
    "\n",
    "# predefine full image over runs\n",
    "# y = np.zeros((msk[0].shape[0], vtcdim[-1], nr_runs))\n",
    "y = np.zeros((chuck[0].shape[0], vtcdim[-1], nr_runs))\n",
    "run_nr = np.zeros((vtcdim[-1], nr_runs))\n",
    "\n",
    "for run in np.arange(0,nr_runs):\n",
    "    # get current runpath\n",
    "    fullpath = join(mridat_dir, pp_dir(pp,ses), fn(pp,ses,run+1))\n",
    "\n",
    "    # mask the vtc\n",
    "    _, y[:,:,run] = vtc.read_vtc_msk(fullpath, chuck)\n",
    "    run_nr[:, run] = run + 1\n",
    "\n",
    "# reshape into single dim\n",
    "run_nr = run_nr.reshape((-1),order='F')\n",
    "y = y.reshape((y.shape[0], -1), order='F').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94911e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprecreat a empty image with the dimension\n",
    "#  of the full vtc - for plotting purpuses\n",
    "rec_img = np.zeros(vtc.get_vtc_dims(head))\n",
    "    \n",
    "# fill in chuck in reconstructed image\n",
    "rec_img[chuck] = y[run_nr == 5].transpose()\n",
    "    \n",
    "# finaly show the full picture\n",
    "plt.imshow(rec_img[:,:,20,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# artifically make longer\n",
    "X = np.repeat(X, 1000, axis=0)\n",
    "y = np.repeat(y, 1000)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "st_time = time.time()\n",
    "regr.fit(X, y)\n",
    "en_time = time.time()\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X) # on same\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y, y_pred))\n",
    "\n",
    "print(f\"\\n\\nTime elepsed: {en_time - st_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac50d0",
   "metadata": {},
   "source": [
    "## test with multi output regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a00943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn import datasets, linear_model\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Load the diabetes dataset\n",
    "# X, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# # artifically make longer\n",
    "# X = np.repeat(X, 10, axis=0)\n",
    "# y = np.repeat(y, 10)\n",
    "\n",
    "# # add muli output\n",
    "# nr_outputs = 10000\n",
    "# y_array = np.empty((len(y),nr_outputs))\n",
    "# for i in range(nr_outputs):\n",
    "#     noise = np.random.normal(0,1,len(y))\n",
    "#     y_array[:,i] = (y + i) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"X_shape: {X.shape}, y_shape: {y_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create linear regression object\n",
    "# regr = linear_model.LinearRegression()\n",
    "# #regr = linear_model.Ridge()\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# st_time = time.time()\n",
    "# regr.fit(X, y_array)\n",
    "\n",
    "# # Make predictions using the testing set\n",
    "# y_pred = regr.predict(X) # on same\n",
    "\n",
    "# en_time = time.time()\n",
    "\n",
    "# # The coefficients\n",
    "# print(\"Coefficients: \\n\", regr.coef_[:5,:])\n",
    "# # The mean squared error\n",
    "# print(\"Mean squared error: %.2f\" % mean_squared_error(y_array, y_pred))\n",
    "# # The coefficient of determination: 1 is perfect prediction\n",
    "# print(\"Coefficient of determination: %.2f\" % r2_score(y_array, y_pred))\n",
    "\n",
    "# print(f\"\\n\\nTime elepsed: {en_time - st_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f22dd49",
   "metadata": {},
   "source": [
    "### Naive approach, looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a326b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predefine y_ped to fill in later\n",
    "# y_pred = np.empty(y_array.shape)\n",
    "# coefs = np.empty((y_array.shape[1], X.shape[1]))\n",
    "\n",
    "# # Create linear regression object\n",
    "# regr = linear_model.LinearRegression()\n",
    "\n",
    "# regdict = {}\n",
    "# # Train the model using the training sets\n",
    "# st_time = time.time()\n",
    "# for i in range(y_array.shape[1]):\n",
    "#     regr.fit(X, y_array[:,i])\n",
    "#     y_pred[:,i] = regr.predict(X)\n",
    "#     coefs[i,:] = regr.coef_\n",
    "# en_time = time.time()\n",
    "\n",
    "# # The coefficients\n",
    "# print(\"Coefficients: \\n\", coefs[:5,:])\n",
    "# # The mean squared error\n",
    "# print(\"Mean squared error: %.2f\" % mean_squared_error(y_array, y_pred))\n",
    "# # The coefficient of determination: 1 is perfect prediction\n",
    "# print(\"Coefficient of determination: %.2f\" % r2_score(y_array, y_pred))\n",
    "\n",
    "# print(f\"\\n\\nTime elepsed: {en_time - st_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
